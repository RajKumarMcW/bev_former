/media/ava/DATA2/Raj/rajkumar/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
projects.mmdet3d_plugin
2024-06-03 10:55:22,227 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.8
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.8
MMDetection: 2.26.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc4+bd0878a
spconv2.0: False
------------------------------------------------------------

2024-06-03 10:55:22,962 - mmdet - INFO - Distributed training: True
2024-06-03 10:55:23,685 - mmdet - INFO - Config:
point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'CustomNuScenesDataset'
data_root = './data/nuscenes/'
input_modality = dict(
    use_lidar=False,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=True)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='CustomCollect3D', keys=['gt_bboxes_3d', 'gt_labels_3d', 'img'])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1600, 900),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='CustomCollect3D', keys=['img'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='CustomNuScenesDataset',
        data_root='./data/nuscenes/',
        ann_file='./data/nuscenes/nuscenes_infos_temporal_train.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='CustomCollect3D',
                keys=['gt_bboxes_3d', 'gt_labels_3d', 'img'])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=False,
        box_type_3d='LiDAR',
        use_valid_flag=True,
        bev_size=(50, 50),
        queue_length=3),
    val=dict(
        type='CustomNuScenesDataset',
        ann_file='./data/nuscenes/nuscenes_infos_temporal_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1600, 900),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
                    dict(type='PadMultiViewImage', size_divisor=32),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='CustomCollect3D', keys=['img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        data_root='./data/nuscenes/',
        bev_size=(50, 50),
        samples_per_gpu=1),
    test=dict(
        type='CustomNuScenesDataset',
        data_root='./data/nuscenes/',
        ann_file='./data/nuscenes/nuscenes_infos_temporal_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1600, 900),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
                    dict(type='PadMultiViewImage', size_divisor=32),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='CustomCollect3D', keys=['img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        bev_size=(50, 50)),
    shuffler_sampler=dict(type='DistributedGroupSampler'),
    nonshuffler_sampler=dict(type='DistributedSampler'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(type='LoadMultiViewImageFromFiles', to_float32=True),
        dict(
            type='NormalizeMultiviewImage',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True),
        dict(
            type='MultiScaleFlipAug3D',
            img_scale=(1600, 900),
            pts_scale_ratio=1,
            flip=False,
            transforms=[
                dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
                dict(type='PadMultiViewImage', size_divisor=32),
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ],
                    with_label=False),
                dict(type='CustomCollect3D', keys=['img'])
            ])
    ])
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=1,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/bevformer_tiny'
load_from = None
resume_from = None
workflow = [('train', 1)]
plugin = True
plugin_dir = 'projects/mmdet3d_plugin/'
voxel_size = [0.2, 0.2, 8]
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
_dim_ = 256
_pos_dim_ = 128
_ffn_dim_ = 512
_num_levels_ = 1
bev_h_ = 50
bev_w_ = 50
queue_length = 3
model = dict(
    type='BEVFormer',
    export=False,
    use_grid_mask=True,
    video_test_mode=True,
    pretrained=dict(img='torchvision://resnet50'),
    img_backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(3, ),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='pytorch'),
    img_neck=dict(
        type='FPN',
        in_channels=[2048],
        out_channels=256,
        start_level=0,
        add_extra_convs='on_output',
        num_outs=1,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='BEVFormerHead',
        bev_h=50,
        bev_w=50,
        num_query=900,
        num_classes=10,
        in_channels=256,
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        transformer=dict(
            type='PerceptionTransformer',
            rotate_prev_bev=True,
            use_shift=True,
            use_can_bus=True,
            embed_dims=256,
            encoder=dict(
                type='BEVFormerEncoder',
                num_layers=3,
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                num_points_in_pillar=4,
                return_intermediate=False,
                transformerlayers=dict(
                    type='BEVFormerLayer',
                    attn_cfgs=[
                        dict(
                            type='TemporalSelfAttention',
                            embed_dims=256,
                            num_levels=1),
                        dict(
                            type='SpatialCrossAttention',
                            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                            deformable_attention=dict(
                                type='MSDeformableAttention3D',
                                embed_dims=256,
                                num_points=8,
                                num_levels=1),
                            embed_dims=256)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm'))),
            decoder=dict(
                type='DetectionTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='CustomMSDeformableAttention',
                            embed_dims=256,
                            num_levels=1)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        bbox_coder=dict(
            type='NMSFreeCoder',
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            max_num=300,
            voxel_size=[0.2, 0.2, 8],
            num_classes=10),
        positional_encoding=dict(
            type='LearnedPositionalEncoding',
            num_feats=128,
            row_num_embed=50,
            col_num_embed=50),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0.0)),
    train_cfg=dict(
        pts=dict(
            grid_size=[512, 512, 1],
            voxel_size=[0.2, 0.2, 8],
            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            out_size_factor=4,
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0.0),
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]))))
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    paramwise_cfg=dict(custom_keys=dict(img_backbone=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
total_epochs = 24
runner = dict(type='EpochBasedRunner', max_epochs=24)
gpu_ids = range(0, 1)

2024-06-03 10:55:23,686 - mmdet - INFO - Set random seed to 0, deterministic: True
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/rajkumar/lib/python3.8/site-packages/mmdet3d/models/detectors/mvx_two_stage.py:88: UserWarning: DeprecationWarning: pretrained is a deprecated key, please consider using init_cfg.
  warnings.warn('DeprecationWarning: pretrained is a deprecated '
2024-06-03 10:55:23,959 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
2024-06-03 10:55:23,959 - mmcv - INFO - load model from: torchvision://resnet50
2024-06-03 10:55:23,959 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50
2024-06-03 10:55:24,020 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2024-06-03 10:55:24,035 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2024-06-03 10:55:24,048 - mmdet - INFO - Model:
BEVFormer(
  (pts_bbox_head): BEVFormerHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): LearnedPositionalEncoding(num_feats=128, row_num_embed=50, col_num_embed=50)
    (transformer): PerceptionTransformer(
      (encoder): BEVFormerEncoder(
        (layers): ModuleList(
          (0): BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (deformable_attention): MSDeformableAttention3D(
                  (sampling_offsets): Linear(in_features=256, out_features=128, bias=True)
                  (attention_weights): Linear(in_features=256, out_features=64, bias=True)
                  (value_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (deformable_attention): MSDeformableAttention3D(
                  (sampling_offsets): Linear(in_features=256, out_features=128, bias=True)
                  (attention_weights): Linear(in_features=256, out_features=64, bias=True)
                  (value_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (deformable_attention): MSDeformableAttention3D(
                  (sampling_offsets): Linear(in_features=256, out_features=128, bias=True)
                  (attention_weights): Linear(in_features=256, out_features=64, bias=True)
                  (value_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (decoder): DetectionTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=3, bias=True)
      (can_bus_mlp): Sequential(
        (0): Linear(in_features=18, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=256, bias=True)
        (3): ReLU(inplace=True)
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (cls_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (bev_embedding): Embedding(2500, 256)
    (query_embedding): Embedding(900, 512)
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (grid_mask): GridMask()
)
WARNING!!!!, Only can be used for obtain inference speed!!!!
2024-06-03 10:55:25,768 - mmdet - INFO - Start running, host: ava@benz, work_dir: /media/ava/DATA2/Raj/BEVFormer/work_dirs/bevformer_tiny
2024-06-03 10:55:25,769 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2024-06-03 10:55:25,769 - mmdet - INFO - workflow: [('train', 1)], max: 24 epochs
2024-06-03 10:55:25,769 - mmdet - INFO - Checkpoints will be saved to /media/ava/DATA2/Raj/BEVFormer/work_dirs/bevformer_tiny by HardDiskBackend.
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/transformer.py:140: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)
  shift = bev_queries.new_tensor(
/media/ava/DATA2/Raj/rajkumar/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
{'loss_cls': tensor([2.3638], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.9790, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.4647], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8624, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.4584], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8879, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([2.1995], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8625, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([2.2831], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.8266, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([2.3168], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.9395, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:34,538 - mmdet - INFO - Epoch [1][1/323]	lr: 6.667e-05, eta: 18:47:20, time: 8.727, data_time: 5.025, memory: 2971, loss_cls: 2.3638, loss_bbox: 1.9790, d0.loss_cls: 2.4647, d0.loss_bbox: 1.8624, d1.loss_cls: 2.4584, d1.loss_bbox: 1.8879, d2.loss_cls: 2.1995, d2.loss_bbox: 1.8625, d3.loss_cls: 2.2831, d3.loss_bbox: 1.8266, d4.loss_cls: 2.3168, d4.loss_bbox: 1.9395, loss: 25.4444, grad_norm: 35.4332
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/models/utils/grid_mask.py:114: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)
  mask = torch.from_numpy(mask).to(x.dtype).cuda()
{'loss_cls': tensor([2.1826], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.9124, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.4743], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.9515, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.3541], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.9463, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.9930], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9530, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.9804], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9490, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([2.1878], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.9636, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:34,954 - mmdet - INFO - Epoch [1][2/323]	lr: 6.693e-05, eta: 9:50:25, time: 0.415, data_time: 0.042, memory: 3360, loss_cls: 2.1826, loss_bbox: 1.9124, d0.loss_cls: 2.4743, d0.loss_bbox: 1.9515, d1.loss_cls: 2.3541, d1.loss_bbox: 1.9463, d2.loss_cls: 1.9930, d2.loss_bbox: 1.9530, d3.loss_cls: 1.9804, d3.loss_bbox: 1.9490, d4.loss_cls: 2.1878, d4.loss_bbox: 1.9636, loss: 24.8480, grad_norm: 42.3713
{'loss_cls': tensor([1.9885], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.9722, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.2592], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(2.0044, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.1146], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.9113, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.9923], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9318, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.9952], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9090, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([2.0737], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.9124, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:35,333 - mmdet - INFO - Epoch [1][3/323]	lr: 6.720e-05, eta: 6:49:51, time: 0.379, data_time: 0.014, memory: 3360, loss_cls: 1.9885, loss_bbox: 1.9722, d0.loss_cls: 2.2592, d0.loss_bbox: 2.0044, d1.loss_cls: 2.1146, d1.loss_bbox: 1.9113, d2.loss_cls: 1.9923, d2.loss_bbox: 1.9318, d3.loss_cls: 1.9952, d3.loss_bbox: 1.9090, d4.loss_cls: 2.0737, d4.loss_bbox: 1.9124, loss: 24.0645, grad_norm: 64.6946
{'loss_cls': tensor([1.9047], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.7634, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.2848], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8768, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.1740], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.7456, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.9168], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8325, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.9126], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.7103, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.8724], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.7972, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:35,709 - mmdet - INFO - Epoch [1][4/323]	lr: 6.747e-05, eta: 5:19:29, time: 0.376, data_time: 0.018, memory: 3360, loss_cls: 1.9047, loss_bbox: 1.7634, d0.loss_cls: 2.2848, d0.loss_bbox: 1.8768, d1.loss_cls: 2.1740, d1.loss_bbox: 1.7456, d2.loss_cls: 1.9168, d2.loss_bbox: 1.8325, d3.loss_cls: 1.9126, d3.loss_bbox: 1.7103, d4.loss_cls: 1.8724, d4.loss_bbox: 1.7972, loss: 22.7912, grad_norm: 37.5684
{'loss_cls': tensor([1.9045], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(2.1045, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.2726], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.7169, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.1355], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.7449, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.8572], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8173, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.8553], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.7767, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.8207], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(2.0868, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:36,113 - mmdet - INFO - Epoch [1][5/323]	lr: 6.773e-05, eta: 4:26:00, time: 0.404, data_time: 0.022, memory: 3360, loss_cls: 1.9045, loss_bbox: 2.1045, d0.loss_cls: 2.2726, d0.loss_bbox: 1.7169, d1.loss_cls: 2.1355, d1.loss_bbox: 1.7449, d2.loss_cls: 1.8572, d2.loss_bbox: 1.8173, d3.loss_cls: 1.8553, d3.loss_bbox: 1.7767, d4.loss_cls: 1.8207, d4.loss_bbox: 2.0868, loss: 23.0928, grad_norm: 52.2196
{'loss_cls': tensor([1.9714], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.7105, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.0825], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.7659, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.0723], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.6552, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([2.0142], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.6991, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([2.0456], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.6553, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.9334], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.6445, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:36,530 - mmdet - INFO - Epoch [1][6/323]	lr: 6.800e-05, eta: 3:50:34, time: 0.415, data_time: 0.015, memory: 3360, loss_cls: 1.9714, loss_bbox: 1.7105, d0.loss_cls: 2.0825, d0.loss_bbox: 1.7659, d1.loss_cls: 2.0723, d1.loss_bbox: 1.6552, d2.loss_cls: 2.0142, d2.loss_bbox: 1.6991, d3.loss_cls: 2.0456, d3.loss_bbox: 1.6553, d4.loss_cls: 1.9334, d4.loss_bbox: 1.6445, loss: 22.2497, grad_norm: 25.2350
{'loss_cls': tensor([1.8636], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.7864, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.1232], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(2.0217, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([2.0585], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.9128, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.8864], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9234, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.9110], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9476, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.8575], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.7375, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:36,931 - mmdet - INFO - Epoch [1][7/323]	lr: 6.827e-05, eta: 3:25:01, time: 0.402, data_time: 0.017, memory: 3360, loss_cls: 1.8636, loss_bbox: 1.7864, d0.loss_cls: 2.1232, d0.loss_bbox: 2.0217, d1.loss_cls: 2.0585, d1.loss_bbox: 1.9128, d2.loss_cls: 1.8864, d2.loss_bbox: 1.9234, d3.loss_cls: 1.9110, d3.loss_bbox: 1.9476, d4.loss_cls: 1.8575, d4.loss_bbox: 1.7375, loss: 23.0297, grad_norm: 35.9769
{'loss_cls': tensor([1.8085], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8939, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([2.0926], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(2.0437, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.9216], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.9546, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.7574], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8781, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.7458], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9628, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.7594], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8004, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:37,357 - mmdet - INFO - Epoch [1][8/323]	lr: 6.853e-05, eta: 3:06:14, time: 0.426, data_time: 0.023, memory: 3360, loss_cls: 1.8085, loss_bbox: 1.8939, d0.loss_cls: 2.0926, d0.loss_bbox: 2.0437, d1.loss_cls: 1.9216, d1.loss_bbox: 1.9546, d2.loss_cls: 1.7574, d2.loss_bbox: 1.8781, d3.loss_cls: 1.7458, d3.loss_bbox: 1.9628, d4.loss_cls: 1.7594, d4.loss_bbox: 1.8004, loss: 22.6187, grad_norm: 62.7347
{'loss_cls': tensor([1.8214], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8822, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.9433], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8205, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.7601], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8110, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.6606], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8349, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.6747], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.7991, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.7008], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8136, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:37,767 - mmdet - INFO - Epoch [1][9/323]	lr: 6.880e-05, eta: 2:51:24, time: 0.410, data_time: 0.016, memory: 3360, loss_cls: 1.8214, loss_bbox: 1.8822, d0.loss_cls: 1.9433, d0.loss_bbox: 1.8205, d1.loss_cls: 1.7601, d1.loss_bbox: 1.8110, d2.loss_cls: 1.6606, d2.loss_bbox: 1.8349, d3.loss_cls: 1.6747, d3.loss_bbox: 1.7991, d4.loss_cls: 1.7008, d4.loss_bbox: 1.8136, loss: 21.5220, grad_norm: 33.2771
{'loss_cls': tensor([1.5315], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.9717, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.9895], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.9470, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.7221], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.9369, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.4693], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9895, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.5076], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(2.0104, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.5046], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8494, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:38,198 - mmdet - INFO - Epoch [1][10/323]	lr: 6.907e-05, eta: 2:39:48, time: 0.430, data_time: 0.017, memory: 3360, loss_cls: 1.5315, loss_bbox: 1.9717, d0.loss_cls: 1.9895, d0.loss_bbox: 1.9470, d1.loss_cls: 1.7221, d1.loss_bbox: 1.9369, d2.loss_cls: 1.4693, d2.loss_bbox: 1.9895, d3.loss_cls: 1.5076, d3.loss_bbox: 2.0104, d4.loss_cls: 1.5046, d4.loss_bbox: 1.8494, loss: 21.4295, grad_norm: 49.2681
{'loss_cls': tensor([1.5165], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(2.3394, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.8424], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(2.1771, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.4103], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(2.3330, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.2370], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(2.2847, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.2494], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(2.2575, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.4193], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(2.2801, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:38,596 - mmdet - INFO - Epoch [1][11/323]	lr: 6.933e-05, eta: 2:29:56, time: 0.399, data_time: 0.019, memory: 3360, loss_cls: 1.5165, loss_bbox: 2.3394, d0.loss_cls: 1.8424, d0.loss_bbox: 2.1771, d1.loss_cls: 1.4103, d1.loss_bbox: 2.3330, d2.loss_cls: 1.2370, d2.loss_bbox: 2.2847, d3.loss_cls: 1.2494, d3.loss_bbox: 2.2575, d4.loss_cls: 1.4193, d4.loss_bbox: 2.2801, loss: 22.3468, grad_norm: 52.7764
{'loss_cls': tensor([1.5513], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8824, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.9109], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.9385, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.5206], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.9820, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.3923], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8771, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.3763], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9475, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.4548], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8742, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:39,022 - mmdet - INFO - Epoch [1][12/323]	lr: 6.960e-05, eta: 2:22:00, time: 0.426, data_time: 0.015, memory: 3372, loss_cls: 1.5513, loss_bbox: 1.8824, d0.loss_cls: 1.9109, d0.loss_bbox: 1.9385, d1.loss_cls: 1.5206, d1.loss_bbox: 1.9820, d2.loss_cls: 1.3923, d2.loss_bbox: 1.8771, d3.loss_cls: 1.3763, d3.loss_bbox: 1.9475, d4.loss_cls: 1.4548, d4.loss_bbox: 1.8742, loss: 20.7080, grad_norm: 42.6992
{'loss_cls': tensor([1.7255], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.7919, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.9690], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.7631, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.9138], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.7971, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.8206], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.7787, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.8596], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.7047, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.8235], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.7807, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:39,420 - mmdet - INFO - Epoch [1][13/323]	lr: 6.987e-05, eta: 2:15:00, time: 0.398, data_time: 0.018, memory: 3372, loss_cls: 1.7255, loss_bbox: 1.7919, d0.loss_cls: 1.9690, d0.loss_bbox: 1.7631, d1.loss_cls: 1.9138, d1.loss_bbox: 1.7971, d2.loss_cls: 1.8206, d2.loss_bbox: 1.7787, d3.loss_cls: 1.8596, d3.loss_bbox: 1.7047, d4.loss_cls: 1.8235, d4.loss_bbox: 1.7807, loss: 21.7283, grad_norm: 29.5527
{'loss_cls': tensor([1.6873], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.7215, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.8762], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8539, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.6347], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.7596, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.6260], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9895, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.6358], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.8903, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.6236], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8087, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:40,003 - mmdet - INFO - Epoch [1][14/323]	lr: 7.013e-05, eta: 2:10:43, time: 0.582, data_time: 0.174, memory: 3372, loss_cls: 1.6873, loss_bbox: 1.7215, d0.loss_cls: 1.8762, d0.loss_bbox: 1.8539, d1.loss_cls: 1.6347, d1.loss_bbox: 1.7596, d2.loss_cls: 1.6260, d2.loss_bbox: 1.9895, d3.loss_cls: 1.6358, d3.loss_bbox: 1.8903, d4.loss_cls: 1.6236, d4.loss_bbox: 1.8087, loss: 21.1071, grad_norm: 49.4658
{'loss_cls': tensor([1.4224], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.9326, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.7821], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8271, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.5925], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8781, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.4751], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9346, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.3932], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9382, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.4275], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.9949, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:40,423 - mmdet - INFO - Epoch [1][15/323]	lr: 7.040e-05, eta: 2:05:36, time: 0.420, data_time: 0.015, memory: 3372, loss_cls: 1.4224, loss_bbox: 1.9326, d0.loss_cls: 1.7821, d0.loss_bbox: 1.8271, d1.loss_cls: 1.5925, d1.loss_bbox: 1.8781, d2.loss_cls: 1.4751, d2.loss_bbox: 1.9346, d3.loss_cls: 1.3932, d3.loss_bbox: 1.9382, d4.loss_cls: 1.4275, d4.loss_bbox: 1.9949, loss: 20.5983, grad_norm: 55.0971
{'loss_cls': tensor([1.2129], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8071, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.5990], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.6022, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.2676], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.7049, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.1420], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8770, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.1529], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.7350, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.1729], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.7157, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:40,919 - mmdet - INFO - Epoch [1][16/323]	lr: 7.067e-05, eta: 2:01:43, time: 0.496, data_time: 0.096, memory: 3372, loss_cls: 1.2129, loss_bbox: 1.8071, d0.loss_cls: 1.5990, d0.loss_bbox: 1.6022, d1.loss_cls: 1.2676, d1.loss_bbox: 1.7049, d2.loss_cls: 1.1420, d2.loss_bbox: 1.8770, d3.loss_cls: 1.1529, d3.loss_bbox: 1.7350, d4.loss_cls: 1.1729, d4.loss_bbox: 1.7157, loss: 17.9892, grad_norm: 34.0590
{'loss_cls': tensor([1.3891], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(2.0423, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.6314], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.7711, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.5505], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8238, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.4542], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8386, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.4016], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.9238, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.3763], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(2.0288, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:41,903 - mmdet - INFO - Epoch [1][17/323]	lr: 7.093e-05, eta: 2:02:01, time: 0.984, data_time: 0.591, memory: 3372, loss_cls: 1.3891, loss_bbox: 2.0423, d0.loss_cls: 1.6314, d0.loss_bbox: 1.7711, d1.loss_cls: 1.5505, d1.loss_bbox: 1.8238, d2.loss_cls: 1.4542, d2.loss_bbox: 1.8386, d3.loss_cls: 1.4016, d3.loss_bbox: 1.9238, d4.loss_cls: 1.3763, d4.loss_bbox: 2.0288, loss: 20.2316, grad_norm: 44.4697
{'loss_cls': tensor([1.6552], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8693, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.8165], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.7789, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.7744], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8453, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.7254], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.7037, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.7485], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.8688, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.6474], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8689, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:42,787 - mmdet - INFO - Epoch [1][18/323]	lr: 7.120e-05, eta: 2:01:32, time: 0.883, data_time: 0.462, memory: 3372, loss_cls: 1.6552, loss_bbox: 1.8693, d0.loss_cls: 1.8165, d0.loss_bbox: 1.7789, d1.loss_cls: 1.7744, d1.loss_bbox: 1.8453, d2.loss_cls: 1.7254, d2.loss_bbox: 1.7037, d3.loss_cls: 1.7485, d3.loss_bbox: 1.8688, d4.loss_cls: 1.6474, d4.loss_bbox: 1.8689, loss: 21.3023, grad_norm: 26.2230
{'loss_cls': tensor([1.2356], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(2.7024, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.4380], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(2.3083, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.2101], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(2.4283, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.2214], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(2.5255, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.1760], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(2.5475, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.2209], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(2.6710, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:43,247 - mmdet - INFO - Epoch [1][19/323]	lr: 7.147e-05, eta: 1:58:15, time: 0.461, data_time: 0.028, memory: 3372, loss_cls: 1.2356, loss_bbox: 2.7024, d0.loss_cls: 1.4380, d0.loss_bbox: 2.3083, d1.loss_cls: 1.2101, d1.loss_bbox: 2.4283, d2.loss_cls: 1.2214, d2.loss_bbox: 2.5255, d3.loss_cls: 1.1760, d3.loss_bbox: 2.5475, d4.loss_cls: 1.2209, d4.loss_bbox: 2.6710, loss: 22.6851, grad_norm: 56.5137
{'loss_cls': tensor([1.7412], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8378, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.8424], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.6566, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.7766], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.6307, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.7597], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.7800, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.7793], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.8564, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.6882], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8367, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:43,657 - mmdet - INFO - Epoch [1][20/323]	lr: 7.173e-05, eta: 1:54:58, time: 0.410, data_time: 0.027, memory: 3372, loss_cls: 1.7412, loss_bbox: 1.8378, d0.loss_cls: 1.8424, d0.loss_bbox: 1.6566, d1.loss_cls: 1.7766, d1.loss_bbox: 1.6307, d2.loss_cls: 1.7597, d2.loss_bbox: 1.7800, d3.loss_cls: 1.7793, d3.loss_bbox: 1.8564, d4.loss_cls: 1.6882, d4.loss_bbox: 1.8367, loss: 21.1856, grad_norm: 23.3299
{'loss_cls': tensor([1.2054], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.7910, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.4882], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8155, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.3610], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.7957, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.2600], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8849, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.2671], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.7937, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.2399], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8335, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:44,671 - mmdet - INFO - Epoch [1][21/323]	lr: 7.200e-05, eta: 1:55:42, time: 1.014, data_time: 0.629, memory: 3372, loss_cls: 1.2054, loss_bbox: 1.7910, d0.loss_cls: 1.4882, d0.loss_bbox: 1.8155, d1.loss_cls: 1.3610, d1.loss_bbox: 1.7957, d2.loss_cls: 1.2600, d2.loss_bbox: 1.8849, d3.loss_cls: 1.2671, d3.loss_bbox: 1.7937, d4.loss_cls: 1.2399, d4.loss_bbox: 1.8335, loss: 18.7358, grad_norm: 28.9973
{'loss_cls': tensor([1.5414], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.9863, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.5788], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.9675, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.5458], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8647, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.5533], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.7134, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.5414], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(2.0251, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.5550], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8837, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:45,460 - mmdet - INFO - Epoch [1][22/323]	lr: 7.227e-05, eta: 1:55:03, time: 0.789, data_time: 0.411, memory: 3372, loss_cls: 1.5414, loss_bbox: 1.9863, d0.loss_cls: 1.5788, d0.loss_bbox: 1.9675, d1.loss_cls: 1.5458, d1.loss_bbox: 1.8647, d2.loss_cls: 1.5533, d2.loss_bbox: 1.7134, d3.loss_cls: 1.5414, d3.loss_bbox: 2.0251, d4.loss_cls: 1.5550, d4.loss_bbox: 1.8837, loss: 20.7566, grad_norm: 53.1973
{'loss_cls': tensor([1.2795], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(2.0379, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.5352], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8648, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.3847], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8752, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.3005], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.9554, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.3372], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(2.0511, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.2883], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8753, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:45,888 - mmdet - INFO - Epoch [1][23/323]	lr: 7.253e-05, eta: 1:52:26, time: 0.428, data_time: 0.020, memory: 3372, loss_cls: 1.2795, loss_bbox: 2.0379, d0.loss_cls: 1.5352, d0.loss_bbox: 1.8648, d1.loss_cls: 1.3847, d1.loss_bbox: 1.8752, d2.loss_cls: 1.3005, d2.loss_bbox: 1.9554, d3.loss_cls: 1.3372, d3.loss_bbox: 2.0511, d4.loss_cls: 1.2883, d4.loss_bbox: 1.8753, loss: 19.7854, grad_norm: 36.8513
{'loss_cls': tensor([1.1696], device='cuda:0', grad_fn=<NanToNumBackward0>), 'loss_bbox': tensor(1.8611, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_cls': tensor([1.3160], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd0.loss_bbox': tensor(1.8692, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_cls': tensor([1.1181], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd1.loss_bbox': tensor(1.8963, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_cls': tensor([1.1666], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd2.loss_bbox': tensor(1.8245, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_cls': tensor([1.1423], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd3.loss_bbox': tensor(1.8422, device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_cls': tensor([1.1539], device='cuda:0', grad_fn=<NanToNumBackward0>), 'd4.loss_bbox': tensor(1.8935, device='cuda:0', grad_fn=<NanToNumBackward0>)}
2024-06-03 10:55:46,311 - mmdet - INFO - Epoch [1][24/323]	lr: 7.280e-05, eta: 1:50:00, time: 0.423, data_time: 0.021, memory: 3372, loss_cls: 1.1696, loss_bbox: 1.8611, d0.loss_cls: 1.3160, d0.loss_bbox: 1.8692, d1.loss_cls: 1.1181, d1.loss_bbox: 1.8963, d2.loss_cls: 1.1666, d2.loss_bbox: 1.8245, d3.loss_cls: 1.1423, d3.loss_bbox: 1.8422, d4.loss_cls: 1.1539, d4.loss_bbox: 1.8935, loss: 18.2532, grad_norm: 27.3133

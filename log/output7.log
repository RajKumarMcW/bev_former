/home/ava/anaconda3/envs/rajkumar/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Config:
 Config (path: configs/bevformer/bevformer_tiny.py): {'point_cloud_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'dataset_type': 'CustomNuScenesDataset', 'data_root': 'data/nuscenes/', 'input_modality': {'use_lidar': False, 'use_camera': True, 'use_radar': False, 'use_map': False, 'use_external': True}, 'file_client_args': {'backend': 'disk'}, 'train_pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'PhotoMetricDistortionMultiViewImage'}, {'type': 'LoadAnnotations3D', 'with_bbox_3d': True, 'with_label_3d': True, 'with_attr_label': False}, {'type': 'ObjectRangeFilter', 'point_cloud_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]}, {'type': 'ObjectNameFilter', 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']}, {'type': 'NormalizeMultiviewImage', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'RandomScaleImageMultiViewImage', 'scales': [0.5]}, {'type': 'PadMultiViewImage', 'size_divisor': 32}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']}, {'type': 'CustomCollect3D', 'keys': ['gt_bboxes_3d', 'gt_labels_3d', 'img']}], 'test_pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'NormalizeMultiviewImage', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'MultiScaleFlipAug3D', 'img_scale': (1600, 900), 'pts_scale_ratio': 1, 'flip': False, 'transforms': [{'type': 'RandomScaleImageMultiViewImage', 'scales': [0.5]}, {'type': 'PadMultiViewImage', 'size_divisor': 32}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'with_label': False}, {'type': 'CustomCollect3D', 'keys': ['img']}]}], 'eval_pipeline': [{'type': 'LoadPointsFromFile', 'coord_type': 'LIDAR', 'load_dim': 5, 'use_dim': 5, 'file_client_args': {'backend': 'disk'}}, {'type': 'LoadPointsFromMultiSweeps', 'sweeps_num': 10, 'file_client_args': {'backend': 'disk'}}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'], 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}], 'data': {'samples_per_gpu': 1, 'workers_per_gpu': 4, 'train': {'type': 'CustomNuScenesDataset', 'data_root': 'data/nuscenes/', 'ann_file': 'data/nuscenes/nuscenes_infos_temporal_train.pkl', 'pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'PhotoMetricDistortionMultiViewImage'}, {'type': 'LoadAnnotations3D', 'with_bbox_3d': True, 'with_label_3d': True, 'with_attr_label': False}, {'type': 'ObjectRangeFilter', 'point_cloud_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]}, {'type': 'ObjectNameFilter', 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']}, {'type': 'NormalizeMultiviewImage', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'RandomScaleImageMultiViewImage', 'scales': [0.5]}, {'type': 'PadMultiViewImage', 'size_divisor': 32}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']}, {'type': 'CustomCollect3D', 'keys': ['gt_bboxes_3d', 'gt_labels_3d', 'img']}], 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'modality': {'use_lidar': False, 'use_camera': True, 'use_radar': False, 'use_map': False, 'use_external': True}, 'test_mode': False, 'box_type_3d': 'LiDAR', 'use_valid_flag': True, 'bev_size': (50, 50), 'queue_length': 3}, 'val': {'type': 'CustomNuScenesDataset', 'ann_file': 'data/nuscenes/nuscenes_infos_temporal_val.pkl', 'pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'NormalizeMultiviewImage', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'MultiScaleFlipAug3D', 'img_scale': (1600, 900), 'pts_scale_ratio': 1, 'flip': False, 'transforms': [{'type': 'RandomScaleImageMultiViewImage', 'scales': [0.5]}, {'type': 'PadMultiViewImage', 'size_divisor': 32}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'with_label': False}, {'type': 'CustomCollect3D', 'keys': ['img']}]}], 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'modality': {'use_lidar': False, 'use_camera': True, 'use_radar': False, 'use_map': False, 'use_external': True}, 'test_mode': True, 'box_type_3d': 'LiDAR', 'data_root': 'data/nuscenes/', 'bev_size': (50, 50), 'samples_per_gpu': 1}, 'test': {'type': 'CustomNuScenesDataset', 'data_root': 'data/nuscenes/', 'ann_file': 'data/nuscenes/nuscenes_infos_temporal_val.pkl', 'pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'NormalizeMultiviewImage', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'MultiScaleFlipAug3D', 'img_scale': (1600, 900), 'pts_scale_ratio': 1, 'flip': False, 'transforms': [{'type': 'RandomScaleImageMultiViewImage', 'scales': [0.5]}, {'type': 'PadMultiViewImage', 'size_divisor': 32}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'with_label': False}, {'type': 'CustomCollect3D', 'keys': ['img']}]}], 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'modality': {'use_lidar': False, 'use_camera': True, 'use_radar': False, 'use_map': False, 'use_external': True}, 'test_mode': True, 'box_type_3d': 'LiDAR', 'bev_size': (50, 50)}, 'shuffler_sampler': {'type': 'DistributedGroupSampler'}, 'nonshuffler_sampler': {'type': 'DistributedSampler'}}, 'evaluation': {'interval': 1, 'pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'NormalizeMultiviewImage', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'MultiScaleFlipAug3D', 'img_scale': (1600, 900), 'pts_scale_ratio': 1, 'flip': False, 'transforms': [{'type': 'RandomScaleImageMultiViewImage', 'scales': [0.5]}, {'type': 'PadMultiViewImage', 'size_divisor': 32}, {'type': 'DefaultFormatBundle3D', 'class_names': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'with_label': False}, {'type': 'CustomCollect3D', 'keys': ['img']}]}]}, 'checkpoint_config': {'interval': 1}, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}, {'type': 'TensorboardLoggerHook'}]}, 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'work_dir': None, 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'plugin': True, 'plugin_dir': 'projects/mmdet3d_plugin/', 'voxel_size': [0.2, 0.2, 8], 'img_norm_cfg': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, '_dim_': 256, '_pos_dim_': 128, '_ffn_dim_': 512, '_num_levels_': 1, 'bev_h_': 50, 'bev_w_': 50, 'queue_length': 3, 'model': {'type': 'BEVFormer', 'use_grid_mask': True, 'video_test_mode': True, 'pretrained': {'img': 'torchvision://resnet50'}, 'img_backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (3,), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': False}, 'norm_eval': True, 'style': 'pytorch'}, 'img_neck': {'type': 'FPN', 'in_channels': [2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_output', 'num_outs': 1, 'relu_before_extra_convs': True}, 'pts_bbox_head': {'type': 'BEVFormerHead', 'bev_h': 50, 'bev_w': 50, 'num_query': 900, 'num_classes': 10, 'in_channels': 256, 'sync_cls_avg_factor': True, 'with_box_refine': True, 'as_two_stage': False, 'transformer': {'type': 'PerceptionTransformer', 'rotate_prev_bev': True, 'use_shift': True, 'use_can_bus': True, 'embed_dims': 256, 'encoder': {'type': 'BEVFormerEncoder', 'num_layers': 3, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'num_points_in_pillar': 4, 'return_intermediate': False, 'transformerlayers': {'type': 'BEVFormerLayer', 'attn_cfgs': [{'type': 'TemporalSelfAttention', 'embed_dims': 256, 'num_levels': 1}, {'type': 'SpatialCrossAttention', 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'deformable_attention': {'type': 'MSDeformableAttention3D', 'embed_dims': 256, 'num_points': 8, 'num_levels': 1}, 'embed_dims': 256}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}, 'decoder': {'type': 'DetectionTransformerDecoder', 'num_layers': 6, 'return_intermediate': True, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': [{'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1}, {'type': 'CustomMSDeformableAttention', 'embed_dims': 256, 'num_levels': 1}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}}, 'bbox_coder': {'type': 'NMSFreeCoder', 'post_center_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0], 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'max_num': 300, 'voxel_size': [0.2, 0.2, 8], 'num_classes': 10}, 'positional_encoding': {'type': 'LearnedPositionalEncoding', 'num_feats': 128, 'row_num_embed': 50, 'col_num_embed': 50}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 0.25}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 0.0}}, 'train_cfg': {'pts': {'grid_size': [512, 512, 1], 'voxel_size': [0.2, 0.2, 8], 'point_cloud_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'out_size_factor': 4, 'assigner': {'type': 'HungarianAssigner3D', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBox3DL1Cost', 'weight': 0.25}, 'iou_cost': {'type': 'IoUCost', 'weight': 0.0}, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]}}}}, 'optimizer': {'type': 'AdamW', 'lr': 0.0002, 'paramwise_cfg': {'custom_keys': {'img_backbone': {'lr_mult': 0.1}}}, 'weight_decay': 0.01}, 'optimizer_config': {'grad_clip': {'max_norm': 35, 'norm_type': 2}}, 'lr_config': {'policy': 'CosineAnnealing', 'warmup': 'linear', 'warmup_iters': 500, 'warmup_ratio': 0.3333333333333333, 'min_lr_ratio': 0.001}, 'total_epochs': 24, 'runner': {'type': 'EpochBasedRunner', 'max_epochs': 24}} 

projects.mmdet3d_plugin
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
load checkpoint from local path: artifacts/bevformer_tiny_epoch_24.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.value_proj.bias

missing keys in source state_dict: pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.to_q.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.to_k.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.to_v.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.proj.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.proj.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.prenorm.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.prenorm.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.mlp.0.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.mlp.0.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.mlp.2.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.mlp.2.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.postnorm.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.global_attention.postnorm.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.to_q.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.to_k.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.to_v.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.proj.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.proj.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.prenorm.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.prenorm.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.mlp.0.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.mlp.0.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.mlp.2.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.mlp.2.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.postnorm.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.global_attention.postnorm.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.to_q.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.to_k.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.to_v.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.proj.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.proj.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.prenorm.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.prenorm.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.mlp.0.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.mlp.0.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.mlp.2.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.mlp.2.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.postnorm.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.global_attention.postnorm.bias

[                                                  ] 0/81, elapsed: 0s, ETA:/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/transformer.py:140: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)
  shift = bev_queries.new_tensor(
/home/ava/anaconda3/envs/rajkumar/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py:57: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  bbox_index = indexs // self.num_classes
[                                  ] 1/81, 0.2 task/s, elapsed: 5s, ETA:   385s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
[                                  ] 2/81, 0.4 task/s, elapsed: 5s, ETA:   193s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>                                 ] 3/81, 0.6 task/s, elapsed: 5s, ETA:   129s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>                                 ] 4/81, 0.8 task/s, elapsed: 5s, ETA:    97s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>                                ] 5/81, 1.0 task/s, elapsed: 5s, ETA:    78s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>                                ] 6/81, 1.2 task/s, elapsed: 5s, ETA:    65s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>                                ] 7/81, 1.3 task/s, elapsed: 5s, ETA:    56s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>                               ] 8/81, 1.5 task/s, elapsed: 5s, ETA:    49s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>                               ] 9/81, 1.6 task/s, elapsed: 6s, ETA:    44s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>                             ] 10/81, 1.8 task/s, elapsed: 6s, ETA:    40s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>                             ] 11/81, 1.9 task/s, elapsed: 6s, ETA:    36s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>                             ] 12/81, 2.1 task/s, elapsed: 6s, ETA:    33s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>                            ] 13/81, 2.2 task/s, elapsed: 6s, ETA:    31s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>                            ] 14/81, 2.3 task/s, elapsed: 6s, ETA:    29s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>                           ] 15/81, 2.5 task/s, elapsed: 6s, ETA:    27s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>                           ] 16/81, 2.5 task/s, elapsed: 6s, ETA:    26s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>                           ] 17/81, 2.6 task/s, elapsed: 6s, ETA:    24s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>                          ] 18/81, 2.8 task/s, elapsed: 7s, ETA:    23s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>                          ] 19/81, 2.9 task/s, elapsed: 7s, ETA:    22s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>                         ] 20/81, 2.9 task/s, elapsed: 7s, ETA:    21s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>                         ] 21/81, 3.0 task/s, elapsed: 7s, ETA:    20s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>                         ] 22/81, 3.1 task/s, elapsed: 7s, ETA:    19s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>                        ] 23/81, 3.2 task/s, elapsed: 7s, ETA:    18s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>                        ] 24/81, 3.2 task/s, elapsed: 7s, ETA:    18s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>                       ] 25/81, 3.3 task/s, elapsed: 8s, ETA:    17s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>                       ] 26/81, 3.4 task/s, elapsed: 8s, ETA:    16s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>                      ] 27/81, 3.5 task/s, elapsed: 8s, ETA:    15s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>                      ] 28/81, 3.5 task/s, elapsed: 8s, ETA:    15s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>                      ] 29/81, 3.6 task/s, elapsed: 8s, ETA:    15s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>                     ] 30/81, 3.7 task/s, elapsed: 8s, ETA:    14s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>                     ] 31/81, 3.7 task/s, elapsed: 8s, ETA:    13s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>                    ] 32/81, 3.7 task/s, elapsed: 9s, ETA:    13s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>                    ] 33/81, 3.8 task/s, elapsed: 9s, ETA:    13s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>                    ] 34/81, 3.9 task/s, elapsed: 9s, ETA:    12s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>                   ] 35/81, 3.9 task/s, elapsed: 9s, ETA:    12s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>                   ] 36/81, 3.9 task/s, elapsed: 9s, ETA:    11s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>                  ] 37/81, 4.0 task/s, elapsed: 9s, ETA:    11s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>                  ] 38/81, 4.1 task/s, elapsed: 9s, ETA:    11s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>                  ] 39/81, 4.1 task/s, elapsed: 9s, ETA:    10s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>                 ] 40/81, 4.1 task/s, elapsed: 10s, ETA:    10s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>                ] 41/81, 4.2 task/s, elapsed: 10s, ETA:    10s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>                ] 42/81, 4.2 task/s, elapsed: 10s, ETA:     9s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>                ] 43/81, 4.3 task/s, elapsed: 10s, ETA:     9s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>               ] 44/81, 4.3 task/s, elapsed: 10s, ETA:     9s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>               ] 45/81, 4.3 task/s, elapsed: 10s, ETA:     8s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>              ] 46/81, 4.4 task/s, elapsed: 10s, ETA:     8s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>              ] 47/81, 4.5 task/s, elapsed: 11s, ETA:     8s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>              ] 48/81, 4.5 task/s, elapsed: 11s, ETA:     7s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>             ] 49/81, 4.5 task/s, elapsed: 11s, ETA:     7s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>             ] 50/81, 4.6 task/s, elapsed: 11s, ETA:     7s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>            ] 51/81, 4.6 task/s, elapsed: 11s, ETA:     6s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>            ] 52/81, 4.6 task/s, elapsed: 11s, ETA:     6s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>            ] 53/81, 4.7 task/s, elapsed: 11s, ETA:     6s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 4.7 task/s, elapsed: 11s, ETA:     6s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 4.8 task/s, elapsed: 12s, ETA:     5s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>          ] 56/81, 4.8 task/s, elapsed: 12s, ETA:     5s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 4.8 task/s, elapsed: 12s, ETA:     5s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 4.9 task/s, elapsed: 12s, ETA:     5s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 4.9 task/s, elapsed: 12s, ETA:     4s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 4.9 task/s, elapsed: 12s, ETA:     4s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>        ] 61/81, 4.9 task/s, elapsed: 12s, ETA:     4s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 5.0 task/s, elapsed: 12s, ETA:     4s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 5.0 task/s, elapsed: 13s, ETA:     4s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 5.0 task/s, elapsed: 13s, ETA:     3s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 5.0 task/s, elapsed: 13s, ETA:     3s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 66/81, 5.0 task/s, elapsed: 13s, ETA:     3s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 5.1 task/s, elapsed: 13s, ETA:     3s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 5.0 task/s, elapsed: 13s, ETA:     3s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 5.1 task/s, elapsed: 14s, ETA:     2s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 5.1 task/s, elapsed: 14s, ETA:     2s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 5.2 task/s, elapsed: 14s, ETA:     2s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 5.1 task/s, elapsed: 14s, ETA:     2s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 5.2 task/s, elapsed: 14s, ETA:     2s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 5.2 task/s, elapsed: 14s, ETA:     1s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 5.2 task/s, elapsed: 14s, ETA:     1s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 5.2 task/s, elapsed: 15s, ETA:     1s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 5.2 task/s, elapsed: 15s, ETA:     1s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 5.3 task/s, elapsed: 15s, ETA:     1s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 5.3 task/s, elapsed: 15s, ETA:     0s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 5.4 task/s, elapsed: 15s, ETA:     0s@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
@@@ torch.Size([6, 2500, 256])
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 5.4 task/s, elapsed: 15s, ETA:     0s
Formating bboxes of pts_bbox
Start to convert detection format...
[                                                  ] 0/81, elapsed: 0s, ETA:[                                 ] 1/81, 31.6 task/s, elapsed: 0s, ETA:     3s[                                 ] 2/81, 30.9 task/s, elapsed: 0s, ETA:     3s[>                                ] 3/81, 31.4 task/s, elapsed: 0s, ETA:     2s[>                                ] 4/81, 31.8 task/s, elapsed: 0s, ETA:     2s[>>                               ] 5/81, 32.1 task/s, elapsed: 0s, ETA:     2s[>>                               ] 6/81, 32.3 task/s, elapsed: 0s, ETA:     2s[>>                               ] 7/81, 32.5 task/s, elapsed: 0s, ETA:     2s[>>>                              ] 8/81, 32.6 task/s, elapsed: 0s, ETA:     2s[>>>                              ] 9/81, 32.7 task/s, elapsed: 0s, ETA:     2s[>>>                             ] 10/81, 32.8 task/s, elapsed: 0s, ETA:     2s[>>>>                            ] 11/81, 32.9 task/s, elapsed: 0s, ETA:     2s[>>>>                            ] 12/81, 33.0 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 13/81, 33.0 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 14/81, 33.0 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 15/81, 33.0 task/s, elapsed: 0s, ETA:     2s[>>>>>>                          ] 16/81, 33.0 task/s, elapsed: 0s, ETA:     2s[>>>>>>                          ] 17/81, 33.0 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 18/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 19/81, 27.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 20/81, 28.2 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 21/81, 28.4 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 22/81, 28.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 23/81, 28.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 24/81, 28.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 25/81, 29.0 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 26/81, 29.1 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 27/81, 29.2 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 28/81, 29.4 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 29/81, 29.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 30/81, 29.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 31/81, 29.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 32/81, 29.8 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 33/81, 29.8 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 34/81, 29.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 35/81, 30.0 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>                  ] 36/81, 30.1 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>                  ] 37/81, 30.2 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 38/81, 30.3 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 39/81, 30.3 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 40/81, 30.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 41/81, 30.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 42/81, 30.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 43/81, 30.6 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 44/81, 30.6 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 45/81, 30.7 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 46/81, 30.8 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 47/81, 30.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 48/81, 30.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 49/81, 31.0 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 50/81, 31.1 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 51/81, 31.1 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 52/81, 31.2 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 53/81, 31.2 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 56/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 31.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 61/81, 31.4 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 31.4 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 31.4 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 66/81, 31.5 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 31.7 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 31.7 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 31.7 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 31.7 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 31.8 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 31.8 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 31.9 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 31.9 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 31.9 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 31.9 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 32.0 task/s, elapsed: 3s, ETA:     0s
Results writes to test/bevformer_tiny/Mon_May_27_23_16_23_2024/pts_bbox/results_nusc.json
Evaluating bboxes of pts_bbox
======
Loading NuScenes tables for version v1.0-mini...
23 category,
8 attribute,
4 visibility,
911 instance,
12 sensor,
120 calibrated_sensor,
31206 ego_pose,
8 log,
10 scene,
404 sample,
31206 sample_data,
18538 sample_annotation,
4 map,
Done loading in 0.291 seconds.
======
Reverse indexing ...
Done reverse indexing in 0.1 seconds.
======
Initializing nuScenes detection evaluation
Loaded results from test/bevformer_tiny/Mon_May_27_23_16_23_2024/pts_bbox/results_nusc.json. Found detections for 81 samples.
Loading annotations for mini_val split from nuScenes version: v1.0-mini
  0%|          | 0/81 [00:00<?, ?it/s] 60%|██████    | 49/81 [00:00<00:00, 486.53it/s]100%|██████████| 81/81 [00:00<00:00, 460.18it/s]
Loaded ground truth annotations for 81 samples.
Filtering predictions
=> Original number of boxes: 10611
=> After distance based filtering: 10597
=> After LIDAR and RADAR points based filtering: 10597
=> After bike rack filtering: 10597
Filtering ground truth annotations
=> Original number of boxes: 4441
=> After distance based filtering: 3785
=> After LIDAR and RADAR points based filtering: 3393
=> After bike rack filtering: 3393
Accumulating metric data...
Calculating metrics...
Saving metrics to: test/bevformer_tiny/Mon_May_27_23_16_23_2024/pts_bbox
mAP: 0.0000
mATE: 1.0203
mASE: 0.9490
mAOE: 1.0429
mAVE: 0.9950
mAAE: 0.9781
NDS: 0.0078
Eval time: 1.8s

Per-class results:
Object Class	AP	ATE	ASE	AOE	AVE	AAE
car	0.000	1.000	1.000	1.000	1.000	1.000
truck	0.000	1.000	1.000	1.000	1.000	1.000
bus	0.000	1.000	1.000	1.000	1.000	1.000
trailer	0.000	1.000	1.000	1.000	1.000	1.000
construction_vehicle	0.000	1.000	1.000	1.000	1.000	1.000
pedestrian	0.000	1.203	0.490	1.387	0.960	0.825
motorcycle	0.000	1.000	1.000	1.000	1.000	1.000
bicycle	0.000	1.000	1.000	1.000	1.000	1.000
traffic_cone	0.000	1.000	1.000	nan	nan	nan
barrier	0.000	1.000	1.000	1.000	nan	nan
{'pts_bbox_NuScenes/car_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/car_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/car_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/car_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/car_trans_err': 1.0, 'pts_bbox_NuScenes/car_scale_err': 1.0, 'pts_bbox_NuScenes/car_orient_err': 1.0, 'pts_bbox_NuScenes/car_vel_err': 1.0, 'pts_bbox_NuScenes/car_attr_err': 1.0, 'pts_bbox_NuScenes/mATE': 1.0203, 'pts_bbox_NuScenes/mASE': 0.949, 'pts_bbox_NuScenes/mAOE': 1.0429, 'pts_bbox_NuScenes/mAVE': 0.995, 'pts_bbox_NuScenes/mAAE': 0.9781, 'pts_bbox_NuScenes/truck_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/truck_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/truck_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/truck_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/truck_trans_err': 1.0, 'pts_bbox_NuScenes/truck_scale_err': 1.0, 'pts_bbox_NuScenes/truck_orient_err': 1.0, 'pts_bbox_NuScenes/truck_vel_err': 1.0, 'pts_bbox_NuScenes/truck_attr_err': 1.0, 'pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/construction_vehicle_trans_err': 1.0, 'pts_bbox_NuScenes/construction_vehicle_scale_err': 1.0, 'pts_bbox_NuScenes/construction_vehicle_orient_err': 1.0, 'pts_bbox_NuScenes/construction_vehicle_vel_err': 1.0, 'pts_bbox_NuScenes/construction_vehicle_attr_err': 1.0, 'pts_bbox_NuScenes/bus_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/bus_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/bus_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/bus_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/bus_trans_err': 1.0, 'pts_bbox_NuScenes/bus_scale_err': 1.0, 'pts_bbox_NuScenes/bus_orient_err': 1.0, 'pts_bbox_NuScenes/bus_vel_err': 1.0, 'pts_bbox_NuScenes/bus_attr_err': 1.0, 'pts_bbox_NuScenes/trailer_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/trailer_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/trailer_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/trailer_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/trailer_trans_err': 1.0, 'pts_bbox_NuScenes/trailer_scale_err': 1.0, 'pts_bbox_NuScenes/trailer_orient_err': 1.0, 'pts_bbox_NuScenes/trailer_vel_err': 1.0, 'pts_bbox_NuScenes/trailer_attr_err': 1.0, 'pts_bbox_NuScenes/barrier_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/barrier_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/barrier_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/barrier_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/barrier_trans_err': 1.0, 'pts_bbox_NuScenes/barrier_scale_err': 1.0, 'pts_bbox_NuScenes/barrier_orient_err': 1.0, 'pts_bbox_NuScenes/barrier_vel_err': nan, 'pts_bbox_NuScenes/barrier_attr_err': nan, 'pts_bbox_NuScenes/motorcycle_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/motorcycle_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/motorcycle_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/motorcycle_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/motorcycle_trans_err': 1.0, 'pts_bbox_NuScenes/motorcycle_scale_err': 1.0, 'pts_bbox_NuScenes/motorcycle_orient_err': 1.0, 'pts_bbox_NuScenes/motorcycle_vel_err': 1.0, 'pts_bbox_NuScenes/motorcycle_attr_err': 1.0, 'pts_bbox_NuScenes/bicycle_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/bicycle_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/bicycle_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/bicycle_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/bicycle_trans_err': 1.0, 'pts_bbox_NuScenes/bicycle_scale_err': 1.0, 'pts_bbox_NuScenes/bicycle_orient_err': 1.0, 'pts_bbox_NuScenes/bicycle_vel_err': 1.0, 'pts_bbox_NuScenes/bicycle_attr_err': 1.0, 'pts_bbox_NuScenes/pedestrian_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/pedestrian_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/pedestrian_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/pedestrian_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/pedestrian_trans_err': 1.2029, 'pts_bbox_NuScenes/pedestrian_scale_err': 0.4904, 'pts_bbox_NuScenes/pedestrian_orient_err': 1.3865, 'pts_bbox_NuScenes/pedestrian_vel_err': 0.96, 'pts_bbox_NuScenes/pedestrian_attr_err': 0.8252, 'pts_bbox_NuScenes/traffic_cone_AP_dist_0.5': 0.0, 'pts_bbox_NuScenes/traffic_cone_AP_dist_1.0': 0.0, 'pts_bbox_NuScenes/traffic_cone_AP_dist_2.0': 0.0, 'pts_bbox_NuScenes/traffic_cone_AP_dist_4.0': 0.0, 'pts_bbox_NuScenes/traffic_cone_trans_err': 1.0, 'pts_bbox_NuScenes/traffic_cone_scale_err': 1.0, 'pts_bbox_NuScenes/traffic_cone_orient_err': nan, 'pts_bbox_NuScenes/traffic_cone_vel_err': nan, 'pts_bbox_NuScenes/traffic_cone_attr_err': nan, 'pts_bbox_NuScenes/NDS': 0.007781244778361107, 'pts_bbox_NuScenes/mAP': 0.0}
/home/ava/anaconda3/envs/rajkumar/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(

/home/ava/anaconda3/envs/rajkumar/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
projects.mmdet3d_plugin
2024-05-27 12:49:20,203 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.8
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.8
MMDetection: 2.26.0
MMSegmentation: 0.30.0
MMDetection3D: 1.0.0rc4+921d216
spconv2.0: False
------------------------------------------------------------

2024-05-27 12:49:20,943 - mmdet - INFO - Distributed training: True
2024-05-27 12:49:21,674 - mmdet - INFO - Config:
point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'CustomNuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=False,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=True)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(type='CustomCollect3D', keys=['gt_bboxes_3d', 'gt_labels_3d', 'img'])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1600, 900),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='CustomCollect3D', keys=['img'])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='CustomNuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_temporal_train.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False),
            dict(
                type='ObjectRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='ObjectNameFilter',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='CustomCollect3D',
                keys=['gt_bboxes_3d', 'gt_labels_3d', 'img'])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=False,
        box_type_3d='LiDAR',
        use_valid_flag=True,
        bev_size=(50, 50),
        queue_length=3),
    val=dict(
        type='CustomNuScenesDataset',
        ann_file='data/nuscenes/nuscenes_infos_temporal_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1600, 900),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
                    dict(type='PadMultiViewImage', size_divisor=32),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='CustomCollect3D', keys=['img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        data_root='data/nuscenes/',
        bev_size=(50, 50),
        samples_per_gpu=1),
    test=dict(
        type='CustomNuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_temporal_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1600, 900),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
                    dict(type='PadMultiViewImage', size_divisor=32),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='CustomCollect3D', keys=['img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        bev_size=(50, 50)),
    shuffler_sampler=dict(type='DistributedGroupSampler'),
    nonshuffler_sampler=dict(type='DistributedSampler'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(type='LoadMultiViewImageFromFiles', to_float32=True),
        dict(
            type='NormalizeMultiviewImage',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True),
        dict(
            type='MultiScaleFlipAug3D',
            img_scale=(1600, 900),
            pts_scale_ratio=1,
            flip=False,
            transforms=[
                dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),
                dict(type='PadMultiViewImage', size_divisor=32),
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ],
                    with_label=False),
                dict(type='CustomCollect3D', keys=['img'])
            ])
    ])
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/bevformer_tiny'
load_from = None
resume_from = None
workflow = [('train', 1)]
plugin = True
plugin_dir = 'projects/mmdet3d_plugin/'
voxel_size = [0.2, 0.2, 8]
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
_dim_ = 256
_pos_dim_ = 128
_ffn_dim_ = 512
_num_levels_ = 1
bev_h_ = 50
bev_w_ = 50
queue_length = 3
model = dict(
    type='BEVFormer',
    use_grid_mask=True,
    video_test_mode=True,
    pretrained=dict(img='torchvision://resnet50'),
    img_backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(3, ),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='pytorch'),
    img_neck=dict(
        type='FPN',
        in_channels=[2048],
        out_channels=256,
        start_level=0,
        add_extra_convs='on_output',
        num_outs=1,
        relu_before_extra_convs=True),
    pts_bbox_head=dict(
        type='BEVFormerHead',
        bev_h=50,
        bev_w=50,
        num_query=900,
        num_classes=10,
        in_channels=256,
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        transformer=dict(
            type='PerceptionTransformer',
            rotate_prev_bev=True,
            use_shift=True,
            use_can_bus=True,
            embed_dims=256,
            encoder=dict(
                type='BEVFormerEncoder',
                num_layers=3,
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                num_points_in_pillar=4,
                return_intermediate=False,
                transformerlayers=dict(
                    type='BEVFormerLayer',
                    attn_cfgs=[
                        dict(
                            type='TemporalSelfAttention',
                            embed_dims=256,
                            num_levels=1),
                        dict(
                            type='SpatialCrossAttention',
                            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                            deformable_attention=dict(
                                type='MSDeformableAttention3D',
                                embed_dims=256,
                                num_points=8,
                                num_levels=1),
                            embed_dims=256)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm'))),
            decoder=dict(
                type='DetectionTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='CustomMSDeformableAttention',
                            embed_dims=256,
                            num_levels=1)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        bbox_coder=dict(
            type='NMSFreeCoder',
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            max_num=300,
            voxel_size=[0.2, 0.2, 8],
            num_classes=10),
        positional_encoding=dict(
            type='LearnedPositionalEncoding',
            num_feats=128,
            row_num_embed=50,
            col_num_embed=50),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0.0)),
    train_cfg=dict(
        pts=dict(
            grid_size=[512, 512, 1],
            voxel_size=[0.2, 0.2, 8],
            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            out_size_factor=4,
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0.0),
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]))))
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    paramwise_cfg=dict(custom_keys=dict(img_backbone=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
total_epochs = 24
runner = dict(type='EpochBasedRunner', max_epochs=24)
gpu_ids = range(0, 1)

2024-05-27 12:49:21,674 - mmdet - INFO - Set random seed to 0, deterministic: True
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/ava/anaconda3/envs/rajkumar/lib/python3.8/site-packages/mmdet3d/models/detectors/mvx_two_stage.py:88: UserWarning: DeprecationWarning: pretrained is a deprecated key, please consider using init_cfg.
  warnings.warn('DeprecationWarning: pretrained is a deprecated '
2024-05-27 12:49:21,961 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
2024-05-27 12:49:21,961 - mmcv - INFO - load model from: torchvision://resnet50
2024-05-27 12:49:21,961 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50
2024-05-27 12:49:22,023 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2024-05-27 12:49:22,039 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2024-05-27 12:49:22,052 - mmdet - INFO - Model:
BEVFormer(
  (pts_bbox_head): BEVFormerHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): LearnedPositionalEncoding(num_feats=128, row_num_embed=50, col_num_embed=50)
    (transformer): PerceptionTransformer(
      (encoder): BEVFormerEncoder(
        (layers): ModuleList(
          (0): BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (global_attention): GlobalCrossAttention(
                  (to_q): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (to_k): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (to_v): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (proj): Linear(in_features=256, out_features=256, bias=True)
                  (prenorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (mlp): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Linear(in_features=512, out_features=256, bias=True)
                  )
                  (postnorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (global_attention): GlobalCrossAttention(
                  (to_q): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (to_k): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (to_v): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (proj): Linear(in_features=256, out_features=256, bias=True)
                  (prenorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (mlp): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Linear(in_features=512, out_features=256, bias=True)
                  )
                  (postnorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (global_attention): GlobalCrossAttention(
                  (to_q): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (to_k): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (to_v): Sequential(
                    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (1): Linear(in_features=256, out_features=256, bias=False)
                  )
                  (proj): Linear(in_features=256, out_features=256, bias=True)
                  (prenorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (mlp): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Linear(in_features=512, out_features=256, bias=True)
                  )
                  (postnorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (decoder): DetectionTransformerDecoder(
        (layers): ModuleList(
          (0): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=3, bias=True)
      (can_bus_mlp): Sequential(
        (0): Linear(in_features=18, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=256, bias=True)
        (3): ReLU(inplace=True)
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (cls_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (4): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
      (5): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (bev_embedding): Embedding(2500, 256)
    (query_embedding): Embedding(900, 512)
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (grid_mask): GridMask()
)
WARNING!!!!, Only can be used for obtain inference speed!!!!
2024-05-27 12:49:23,820 - mmdet - INFO - Start running, host: ava@benz, work_dir: /media/ava/DATA2/Raj/BEVFormer/work_dirs/bevformer_tiny
2024-05-27 12:49:23,820 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2024-05-27 12:49:23,820 - mmdet - INFO - workflow: [('train', 1)], max: 24 epochs
2024-05-27 12:49:23,820 - mmdet - INFO - Checkpoints will be saved to /media/ava/DATA2/Raj/BEVFormer/work_dirs/bevformer_tiny by HardDiskBackend.
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/bevformer/modules/transformer.py:140: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)
  shift = bev_queries.new_tensor(
/home/ava/anaconda3/envs/rajkumar/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/models/utils/grid_mask.py:114: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)
  mask = torch.from_numpy(mask).to(x.dtype).cuda()
2024-05-27 12:50:02,080 - mmdet - INFO - Epoch [1][50/323]	lr: 7.973e-05, eta: 1:38:07, time: 0.764, data_time: 0.295, memory: 3502, loss_cls: 1.5418, loss_bbox: 1.9563, d0.loss_cls: 1.5648, d0.loss_bbox: 1.8906, d1.loss_cls: 1.5413, d1.loss_bbox: 1.9053, d2.loss_cls: 1.5025, d2.loss_bbox: 1.9061, d3.loss_cls: 1.5633, d3.loss_bbox: 1.9657, d4.loss_cls: 1.5273, d4.loss_bbox: 2.0014, loss: 20.8664, grad_norm: 41.6268
2024-05-27 12:50:36,482 - mmdet - INFO - Epoch [1][100/323]	lr: 9.307e-05, eta: 1:32:36, time: 0.688, data_time: 0.279, memory: 3502, loss_cls: 1.2740, loss_bbox: 1.9295, d0.loss_cls: 1.2515, d0.loss_bbox: 1.8154, d1.loss_cls: 1.2734, d1.loss_bbox: 1.7953, d2.loss_cls: 1.2686, d2.loss_bbox: 1.9037, d3.loss_cls: 1.2793, d3.loss_bbox: 1.9036, d4.loss_cls: 1.2722, d4.loss_bbox: 1.9215, loss: 18.8879, grad_norm: 38.3279
2024-05-27 12:51:10,275 - mmdet - INFO - Epoch [1][150/323]	lr: 1.064e-04, eta: 1:29:52, time: 0.676, data_time: 0.263, memory: 3502, loss_cls: 1.3106, loss_bbox: 1.9188, d0.loss_cls: 1.2887, d0.loss_bbox: 1.8328, d1.loss_cls: 1.2982, d1.loss_bbox: 1.8180, d2.loss_cls: 1.3018, d2.loss_bbox: 1.8159, d3.loss_cls: 1.3063, d3.loss_bbox: 1.8113, d4.loss_cls: 1.3082, d4.loss_bbox: 1.8439, loss: 18.8546, grad_norm: 43.4178
2024-05-27 12:51:44,760 - mmdet - INFO - Epoch [1][200/323]	lr: 1.197e-04, eta: 1:28:40, time: 0.690, data_time: 0.281, memory: 3502, loss_cls: 1.2217, loss_bbox: 1.7869, d0.loss_cls: 1.1939, d0.loss_bbox: 1.7031, d1.loss_cls: 1.2169, d1.loss_bbox: 1.7243, d2.loss_cls: 1.2123, d2.loss_bbox: 1.7475, d3.loss_cls: 1.2140, d3.loss_bbox: 1.7190, d4.loss_cls: 1.2147, d4.loss_bbox: 1.7464, loss: 17.7009, grad_norm: 36.0286
2024-05-27 12:52:17,818 - mmdet - INFO - Epoch [1][250/323]	lr: 1.331e-04, eta: 1:26:59, time: 0.661, data_time: 0.242, memory: 3502, loss_cls: 1.2409, loss_bbox: 1.9471, d0.loss_cls: 1.1942, d0.loss_bbox: 1.7330, d1.loss_cls: 1.2309, d1.loss_bbox: 1.8067, d2.loss_cls: 1.2298, d2.loss_bbox: 1.9416, d3.loss_cls: 1.2308, d3.loss_bbox: 1.8305, d4.loss_cls: 1.2316, d4.loss_bbox: 1.7972, loss: 18.4142, grad_norm: 41.1436
2024-05-27 12:52:52,028 - mmdet - INFO - Epoch [1][300/323]	lr: 1.464e-04, eta: 1:26:10, time: 0.684, data_time: 0.268, memory: 3502, loss_cls: 1.3055, loss_bbox: 1.8827, d0.loss_cls: 1.2702, d0.loss_bbox: 1.7339, d1.loss_cls: 1.2987, d1.loss_bbox: 1.7961, d2.loss_cls: 1.2983, d2.loss_bbox: 1.7569, d3.loss_cls: 1.3061, d3.loss_bbox: 1.9360, d4.loss_cls: 1.3027, d4.loss_bbox: 1.8582, loss: 18.7453, grad_norm: 47.5456
2024-05-27 12:53:05,622 - mmdet - INFO - Saving checkpoint at 1 epochs
[                                                  ] 0/81, elapsed: 0s, ETA:/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py:57: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  bbox_index = indexs // self.num_classes
[                                  ] 1/81, 1.1 task/s, elapsed: 1s, ETA:    75s/media/ava/DATA2/Raj/BEVFormer/src/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
[                                  ] 2/81, 2.0 task/s, elapsed: 1s, ETA:    41s[>                                 ] 3/81, 2.7 task/s, elapsed: 1s, ETA:    29s[>                                 ] 4/81, 3.2 task/s, elapsed: 1s, ETA:    24s[>>                                ] 5/81, 3.5 task/s, elapsed: 1s, ETA:    22s[>>                                ] 6/81, 4.0 task/s, elapsed: 2s, ETA:    19s[>>                                ] 7/81, 4.4 task/s, elapsed: 2s, ETA:    17s[>>>                               ] 8/81, 4.8 task/s, elapsed: 2s, ETA:    15s[>>>                               ] 9/81, 4.7 task/s, elapsed: 2s, ETA:    15s[>>>>                             ] 10/81, 5.0 task/s, elapsed: 2s, ETA:    14s[>>>>                             ] 11/81, 5.2 task/s, elapsed: 2s, ETA:    13s[>>>>                             ] 12/81, 5.5 task/s, elapsed: 2s, ETA:    13s[>>>>>                            ] 13/81, 5.4 task/s, elapsed: 2s, ETA:    13s[>>>>>                            ] 14/81, 5.6 task/s, elapsed: 3s, ETA:    12s[>>>>>>                           ] 15/81, 5.8 task/s, elapsed: 3s, ETA:    11s[>>>>>>                           ] 16/81, 5.9 task/s, elapsed: 3s, ETA:    11s[>>>>>>                           ] 17/81, 5.8 task/s, elapsed: 3s, ETA:    11s[>>>>>>>                          ] 18/81, 5.9 task/s, elapsed: 3s, ETA:    11s[>>>>>>>                          ] 19/81, 6.1 task/s, elapsed: 3s, ETA:    10s[>>>>>>>>                         ] 20/81, 6.1 task/s, elapsed: 3s, ETA:    10s[>>>>>>>>                         ] 21/81, 6.0 task/s, elapsed: 3s, ETA:    10s[>>>>>>>>                         ] 22/81, 6.1 task/s, elapsed: 4s, ETA:    10s[>>>>>>>>>                        ] 23/81, 6.3 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>                        ] 24/81, 6.4 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>                       ] 25/81, 6.1 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>                       ] 26/81, 6.3 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>>                      ] 27/81, 6.4 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 28/81, 6.5 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 29/81, 6.2 task/s, elapsed: 5s, ETA:     8s[>>>>>>>>>>>>                     ] 30/81, 6.3 task/s, elapsed: 5s, ETA:     8s[>>>>>>>>>>>>                     ] 31/81, 6.4 task/s, elapsed: 5s, ETA:     8s[>>>>>>>>>>>>>                    ] 32/81, 6.5 task/s, elapsed: 5s, ETA:     8s[>>>>>>>>>>>>>                    ] 33/81, 6.3 task/s, elapsed: 5s, ETA:     8s[>>>>>>>>>>>>>                    ] 34/81, 6.4 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>                   ] 35/81, 6.4 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>                   ] 36/81, 6.5 task/s, elapsed: 6s, ETA:     7s[>>>>>>>>>>>>>>>                  ] 37/81, 6.4 task/s, elapsed: 6s, ETA:     7s[>>>>>>>>>>>>>>>                  ] 38/81, 6.5 task/s, elapsed: 6s, ETA:     7s[>>>>>>>>>>>>>>>                  ] 39/81, 6.6 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>                 ] 40/81, 6.6 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>                 ] 41/81, 6.5 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>>                ] 42/81, 6.5 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>>                ] 43/81, 6.6 task/s, elapsed: 7s, ETA:     6s[>>>>>>>>>>>>>>>>>                ] 44/81, 6.7 task/s, elapsed: 7s, ETA:     6s[>>>>>>>>>>>>>>>>>>               ] 45/81, 6.6 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>               ] 46/81, 6.7 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 47/81, 6.8 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 48/81, 6.8 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 49/81, 6.7 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>             ] 50/81, 6.8 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>             ] 51/81, 6.9 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>            ] 52/81, 6.9 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>            ] 53/81, 6.8 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 6.8 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 6.9 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 56/81, 6.9 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 6.8 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 6.8 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 6.9 task/s, elapsed: 9s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 6.9 task/s, elapsed: 9s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 61/81, 6.8 task/s, elapsed: 9s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 6.9 task/s, elapsed: 9s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 6.9 task/s, elapsed: 9s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 7.0 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 6.9 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 66/81, 6.9 task/s, elapsed: 10s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 6.9 task/s, elapsed: 10s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 7.0 task/s, elapsed: 10s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 6.9 task/s, elapsed: 10s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 7.0 task/s, elapsed: 10s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 7.0 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 7.0 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 7.0 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 7.0 task/s, elapsed: 11s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 7.1 task/s, elapsed: 11s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 7.1 task/s, elapsed: 11s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 7.1 task/s, elapsed: 11s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 7.1 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 7.2 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 7.2 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 7.3 task/s, elapsed: 11s, ETA:     0s
Formating bboxes of pts_bbox
Start to convert detection format...
[                                                  ] 0/81, elapsed: 0s, ETA:[                                 ] 1/81, 29.3 task/s, elapsed: 0s, ETA:     3s[                                 ] 2/81, 30.5 task/s, elapsed: 0s, ETA:     3s[>                                ] 3/81, 31.4 task/s, elapsed: 0s, ETA:     2s[>                                ] 4/81, 31.9 task/s, elapsed: 0s, ETA:     2s[>>                               ] 5/81, 32.2 task/s, elapsed: 0s, ETA:     2s[>>                               ] 6/81, 32.4 task/s, elapsed: 0s, ETA:     2s[>>                               ] 7/81, 32.6 task/s, elapsed: 0s, ETA:     2s[>>>                              ] 8/81, 32.7 task/s, elapsed: 0s, ETA:     2s[>>>                              ] 9/81, 32.6 task/s, elapsed: 0s, ETA:     2s[>>>                             ] 10/81, 32.6 task/s, elapsed: 0s, ETA:     2s[>>>>                            ] 11/81, 32.5 task/s, elapsed: 0s, ETA:     2s[>>>>                            ] 12/81, 32.4 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 13/81, 32.3 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 14/81, 32.2 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 15/81, 32.1 task/s, elapsed: 0s, ETA:     2s[>>>>>>                          ] 16/81, 32.0 task/s, elapsed: 0s, ETA:     2s[>>>>>>                          ] 17/81, 32.0 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 18/81, 31.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 19/81, 31.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 20/81, 31.8 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 21/81, 31.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 22/81, 31.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 23/81, 31.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 24/81, 31.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 25/81, 31.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 26/81, 31.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 27/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 28/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 29/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 30/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 31/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 32/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 33/81, 31.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 34/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>                   ] 35/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>                  ] 36/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>                  ] 37/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 38/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 39/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 40/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 41/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 42/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 43/81, 31.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 44/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 45/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 46/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 47/81, 31.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 48/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 49/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 50/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 51/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 52/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 53/81, 31.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 56/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 61/81, 31.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 31.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 31.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 31.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 66/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 31.6 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 31.5 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 31.5 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 31.5 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 31.5 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 31.5 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 31.5 task/s, elapsed: 3s, ETA:     0s
Results writes to val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox/results_nusc.json
Evaluating bboxes of pts_bbox
======
Loading NuScenes tables for version v1.0-mini...
23 category,
8 attribute,
4 visibility,
911 instance,
12 sensor,
120 calibrated_sensor,
31206 ego_pose,
8 log,
10 scene,
404 sample,
31206 sample_data,
18538 sample_annotation,
4 map,
Done loading in 0.420 seconds.
======
Reverse indexing ...
Done reverse indexing in 0.1 seconds.
======
Initializing nuScenes detection evaluation
Loaded results from val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox/results_nusc.json. Found detections for 81 samples.
Loading annotations for mini_val split from nuScenes version: v1.0-mini
  0%|          | 0/81 [00:00<?, ?it/s] 62%|██████▏   | 50/81 [00:00<00:00, 491.28it/s]100%|██████████| 81/81 [00:00<00:00, 465.04it/s]
Loaded ground truth annotations for 81 samples.
Filtering predictions
=> Original number of boxes: 14375
=> After distance based filtering: 14363
=> After LIDAR and RADAR points based filtering: 14363
=> After bike rack filtering: 14363
Filtering ground truth annotations
=> Original number of boxes: 4441
=> After distance based filtering: 3785
=> After LIDAR and RADAR points based filtering: 3393
=> After bike rack filtering: 3393
Accumulating metric data...
Calculating metrics...
Saving metrics to: val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox
mAP: 0.0000
mATE: 1.0353
mASE: 0.9870
mAOE: 1.0618
mAVE: 0.9847
mAAE: 0.9776
NDS: 0.0051
Eval time: 2.6s

Per-class results:
Object Class	AP	ATE	ASE	AOE	AVE	AAE
car	0.000	1.000	1.000	1.000	1.000	1.000
truck	0.000	1.000	1.000	1.000	1.000	1.000
bus	0.000	1.000	1.000	1.000	1.000	1.000
trailer	0.000	1.000	1.000	1.000	1.000	1.000
construction_vehicle	0.000	1.000	1.000	1.000	1.000	1.000
pedestrian	0.000	1.353	0.870	1.556	0.877	0.820
motorcycle	0.000	1.000	1.000	1.000	1.000	1.000
bicycle	0.000	1.000	1.000	1.000	1.000	1.000
traffic_cone	0.000	1.000	1.000	nan	nan	nan
barrier	0.000	1.000	1.000	1.000	nan	nan
2024-05-27 12:53:27,591 - mmdet - INFO - Exp name: bevformer_tiny.py
2024-05-27 12:53:27,591 - mmdet - INFO - Epoch(val) [1][81]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/car_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/car_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/car_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/car_trans_err: 1.0000, pts_bbox_NuScenes/car_scale_err: 1.0000, pts_bbox_NuScenes/car_orient_err: 1.0000, pts_bbox_NuScenes/car_vel_err: 1.0000, pts_bbox_NuScenes/car_attr_err: 1.0000, pts_bbox_NuScenes/mATE: 1.0353, pts_bbox_NuScenes/mASE: 0.9870, pts_bbox_NuScenes/mAOE: 1.0618, pts_bbox_NuScenes/mAVE: 0.9847, pts_bbox_NuScenes/mAAE: 0.9776, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/truck_trans_err: 1.0000, pts_bbox_NuScenes/truck_scale_err: 1.0000, pts_bbox_NuScenes/truck_orient_err: 1.0000, pts_bbox_NuScenes/truck_vel_err: 1.0000, pts_bbox_NuScenes/truck_attr_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_trans_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_scale_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_vel_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_attr_err: 1.0000, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bus_trans_err: 1.0000, pts_bbox_NuScenes/bus_scale_err: 1.0000, pts_bbox_NuScenes/bus_orient_err: 1.0000, pts_bbox_NuScenes/bus_vel_err: 1.0000, pts_bbox_NuScenes/bus_attr_err: 1.0000, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/trailer_trans_err: 1.0000, pts_bbox_NuScenes/trailer_scale_err: 1.0000, pts_bbox_NuScenes/trailer_orient_err: 1.0000, pts_bbox_NuScenes/trailer_vel_err: 1.0000, pts_bbox_NuScenes/trailer_attr_err: 1.0000, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/barrier_trans_err: 1.0000, pts_bbox_NuScenes/barrier_scale_err: 1.0000, pts_bbox_NuScenes/barrier_orient_err: 1.0000, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/motorcycle_trans_err: 1.0000, pts_bbox_NuScenes/motorcycle_scale_err: 1.0000, pts_bbox_NuScenes/motorcycle_orient_err: 1.0000, pts_bbox_NuScenes/motorcycle_vel_err: 1.0000, pts_bbox_NuScenes/motorcycle_attr_err: 1.0000, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 1.0000, pts_bbox_NuScenes/bicycle_scale_err: 1.0000, pts_bbox_NuScenes/bicycle_orient_err: 1.0000, pts_bbox_NuScenes/bicycle_vel_err: 1.0000, pts_bbox_NuScenes/bicycle_attr_err: 1.0000, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/pedestrian_trans_err: 1.3535, pts_bbox_NuScenes/pedestrian_scale_err: 0.8695, pts_bbox_NuScenes/pedestrian_orient_err: 1.5561, pts_bbox_NuScenes/pedestrian_vel_err: 0.8772, pts_bbox_NuScenes/pedestrian_attr_err: 0.8205, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/traffic_cone_trans_err: 1.0000, pts_bbox_NuScenes/traffic_cone_scale_err: 1.0000, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.0051, pts_bbox_NuScenes/mAP: 0.0000
2024-05-27 12:54:05,374 - mmdet - INFO - Epoch [2][50/323]	lr: 1.652e-04, eta: 1:21:05, time: 0.755, data_time: 0.342, memory: 3504, loss_cls: 1.2655, loss_bbox: 1.8266, d0.loss_cls: 1.2321, d0.loss_bbox: 1.6977, d1.loss_cls: 1.2625, d1.loss_bbox: 1.6858, d2.loss_cls: 1.2679, d2.loss_bbox: 1.7066, d3.loss_cls: 1.2672, d3.loss_bbox: 2.0221, d4.loss_cls: 1.2617, d4.loss_bbox: 1.8504, loss: 18.3461, grad_norm: 39.9112
2024-05-27 12:54:37,770 - mmdet - INFO - Epoch [2][100/323]	lr: 1.784e-04, eta: 1:20:22, time: 0.648, data_time: 0.232, memory: 3504, loss_cls: 1.2314, loss_bbox: 1.8853, d0.loss_cls: 1.1854, d0.loss_bbox: 1.6716, d1.loss_cls: 1.2302, d1.loss_bbox: 1.7345, d2.loss_cls: 1.2307, d2.loss_bbox: 1.7722, d3.loss_cls: 1.2362, d3.loss_bbox: 1.8431, d4.loss_cls: 1.2370, d4.loss_bbox: 1.8667, loss: 18.1243, grad_norm: 39.8045
2024-05-27 12:55:11,972 - mmdet - INFO - Epoch [2][150/323]	lr: 1.917e-04, eta: 1:20:09, time: 0.684, data_time: 0.264, memory: 3504, loss_cls: 1.2869, loss_bbox: 1.8755, d0.loss_cls: 1.2473, d0.loss_bbox: 1.7450, d1.loss_cls: 1.2864, d1.loss_bbox: 1.7832, d2.loss_cls: 1.2829, d2.loss_bbox: 1.8256, d3.loss_cls: 1.2896, d3.loss_bbox: 1.8260, d4.loss_cls: 1.2919, d4.loss_bbox: 1.8463, loss: 18.5866, grad_norm: 42.7173
2024-05-27 12:55:45,023 - mmdet - INFO - Epoch [2][200/323]	lr: 1.991e-04, eta: 1:19:36, time: 0.661, data_time: 0.241, memory: 3504, loss_cls: 1.2143, loss_bbox: 1.7866, d0.loss_cls: 1.1741, d0.loss_bbox: 1.6859, d1.loss_cls: 1.2000, d1.loss_bbox: 1.6617, d2.loss_cls: 1.2030, d2.loss_bbox: 1.7039, d3.loss_cls: 1.2062, d3.loss_bbox: 1.7268, d4.loss_cls: 1.2083, d4.loss_bbox: 1.7297, loss: 17.5004, grad_norm: 35.4708
2024-05-27 12:56:19,019 - mmdet - INFO - Epoch [2][250/323]	lr: 1.991e-04, eta: 1:19:15, time: 0.680, data_time: 0.262, memory: 3504, loss_cls: 1.2335, loss_bbox: 1.7936, d0.loss_cls: 1.2251, d0.loss_bbox: 1.7143, d1.loss_cls: 1.2295, d1.loss_bbox: 1.7416, d2.loss_cls: 1.2259, d2.loss_bbox: 1.7169, d3.loss_cls: 1.2280, d3.loss_bbox: 1.7864, d4.loss_cls: 1.2294, d4.loss_bbox: 1.7667, loss: 17.8909, grad_norm: 39.1692
2024-05-27 12:56:52,593 - mmdet - INFO - Epoch [2][300/323]	lr: 1.991e-04, eta: 1:18:47, time: 0.671, data_time: 0.252, memory: 3504, loss_cls: 1.3092, loss_bbox: 1.8221, d0.loss_cls: 1.2583, d0.loss_bbox: 1.6992, d1.loss_cls: 1.2943, d1.loss_bbox: 1.6827, d2.loss_cls: 1.2953, d2.loss_bbox: 1.7001, d3.loss_cls: 1.3062, d3.loss_bbox: 1.7637, d4.loss_cls: 1.3056, d4.loss_bbox: 1.7641, loss: 18.2007, grad_norm: 42.2937
2024-05-27 12:57:06,876 - mmdet - INFO - Saving checkpoint at 2 epochs
[                                                  ] 0/81, elapsed: 0s, ETA:[                                  ] 1/81, 1.6 task/s, elapsed: 1s, ETA:    51s[                                  ] 2/81, 2.7 task/s, elapsed: 1s, ETA:    29s[>                                 ] 3/81, 3.7 task/s, elapsed: 1s, ETA:    21s[>                                 ] 4/81, 4.4 task/s, elapsed: 1s, ETA:    17s[>>                                ] 5/81, 4.4 task/s, elapsed: 1s, ETA:    17s[>>                                ] 6/81, 4.8 task/s, elapsed: 1s, ETA:    16s[>>                                ] 7/81, 5.2 task/s, elapsed: 1s, ETA:    14s[>>>                               ] 8/81, 5.6 task/s, elapsed: 1s, ETA:    13s[>>>                               ] 9/81, 5.3 task/s, elapsed: 2s, ETA:    14s[>>>>                             ] 10/81, 5.6 task/s, elapsed: 2s, ETA:    13s[>>>>                             ] 11/81, 5.9 task/s, elapsed: 2s, ETA:    12s[>>>>                             ] 12/81, 6.1 task/s, elapsed: 2s, ETA:    11s[>>>>>                            ] 13/81, 5.9 task/s, elapsed: 2s, ETA:    12s[>>>>>                            ] 14/81, 6.1 task/s, elapsed: 2s, ETA:    11s[>>>>>>                           ] 15/81, 6.2 task/s, elapsed: 2s, ETA:    11s[>>>>>>                           ] 16/81, 6.4 task/s, elapsed: 2s, ETA:    10s[>>>>>>                           ] 17/81, 6.1 task/s, elapsed: 3s, ETA:    10s[>>>>>>>                          ] 18/81, 6.3 task/s, elapsed: 3s, ETA:    10s[>>>>>>>                          ] 19/81, 6.4 task/s, elapsed: 3s, ETA:    10s[>>>>>>>>                         ] 20/81, 6.5 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>                         ] 21/81, 6.3 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>                         ] 22/81, 6.5 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>>                        ] 23/81, 6.6 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>>                        ] 24/81, 6.7 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>                       ] 25/81, 6.5 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>                       ] 26/81, 6.6 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 27/81, 6.7 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 28/81, 6.8 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 29/81, 6.7 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>>                     ] 30/81, 6.8 task/s, elapsed: 4s, ETA:     7s[>>>>>>>>>>>>                     ] 31/81, 6.9 task/s, elapsed: 4s, ETA:     7s[>>>>>>>>>>>>>                    ] 32/81, 7.0 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>                    ] 33/81, 6.9 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>                    ] 34/81, 7.0 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>                   ] 35/81, 7.1 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>                   ] 36/81, 7.1 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>                  ] 37/81, 7.0 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>                  ] 38/81, 7.1 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>                  ] 39/81, 7.1 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>>                 ] 40/81, 7.2 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>                 ] 41/81, 7.1 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>>                ] 42/81, 7.1 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>                ] 43/81, 7.2 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>                ] 44/81, 7.2 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>               ] 45/81, 7.2 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>               ] 46/81, 7.2 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 47/81, 7.3 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 48/81, 7.3 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 49/81, 7.2 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>             ] 50/81, 7.3 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>             ] 51/81, 7.3 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>            ] 52/81, 7.4 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>            ] 53/81, 7.3 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 7.3 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 7.3 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 56/81, 7.4 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 7.2 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 7.4 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 61/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 7.4 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 7.4 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 66/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 7.4 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 7.4 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 7.4 task/s, elapsed: 9s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 7.4 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 7.4 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 7.4 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 7.4 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 7.4 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 7.5 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 7.4 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 7.5 task/s, elapsed: 10s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 7.5 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 7.5 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 7.6 task/s, elapsed: 11s, ETA:     0s
Formating bboxes of pts_bbox
Start to convert detection format...
[                                                  ] 0/81, elapsed: 0s, ETA:[                                 ] 1/81, 28.4 task/s, elapsed: 0s, ETA:     3s[                                 ] 2/81, 27.7 task/s, elapsed: 0s, ETA:     3s[>                                ] 3/81, 27.4 task/s, elapsed: 0s, ETA:     3s[>                                ] 4/81, 27.3 task/s, elapsed: 0s, ETA:     3s[>>                               ] 5/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>                               ] 6/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>                               ] 7/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>>                              ] 8/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>>                              ] 9/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>>                             ] 10/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>>>                            ] 11/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>>>                            ] 12/81, 27.2 task/s, elapsed: 0s, ETA:     3s[>>>>>                           ] 13/81, 27.4 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 14/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>                           ] 15/81, 27.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>                          ] 16/81, 27.9 task/s, elapsed: 1s, ETA:     2s[>>>>>>                          ] 17/81, 28.0 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 18/81, 28.0 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 19/81, 28.1 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 20/81, 28.1 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 21/81, 28.1 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 22/81, 28.2 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 23/81, 28.2 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 24/81, 28.2 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 25/81, 28.3 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 26/81, 28.3 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 27/81, 28.4 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 28/81, 28.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 29/81, 28.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 30/81, 28.8 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 31/81, 28.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 32/81, 28.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 33/81, 28.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 34/81, 28.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 35/81, 28.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>                  ] 36/81, 28.4 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>                  ] 37/81, 28.4 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>>                 ] 38/81, 28.3 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>>                 ] 39/81, 28.3 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>                 ] 40/81, 28.3 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 41/81, 28.3 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 42/81, 28.4 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 43/81, 28.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 44/81, 28.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 45/81, 28.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 46/81, 29.0 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 47/81, 29.1 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 48/81, 29.2 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 49/81, 29.2 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 50/81, 29.1 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 51/81, 29.1 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 52/81, 29.2 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 53/81, 29.2 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 29.3 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 29.5 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 56/81, 29.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 29.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 29.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 29.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 29.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 61/81, 29.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 29.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 29.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 29.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 29.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 66/81, 29.9 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 30.0 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 30.1 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 30.1 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 30.2 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 30.2 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 30.3 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 30.3 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 30.3 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 30.3 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 30.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 30.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 30.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 30.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 30.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 30.2 task/s, elapsed: 3s, ETA:     0s
Results writes to val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox/results_nusc.json
Evaluating bboxes of pts_bbox
======
Loading NuScenes tables for version v1.0-mini...
23 category,
8 attribute,
4 visibility,
911 instance,
12 sensor,
120 calibrated_sensor,
31206 ego_pose,
8 log,
10 scene,
404 sample,
31206 sample_data,
18538 sample_annotation,
4 map,
Done loading in 0.328 seconds.
======
Reverse indexing ...
Done reverse indexing in 0.1 seconds.
======
Initializing nuScenes detection evaluation
Loaded results from val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox/results_nusc.json. Found detections for 81 samples.
Loading annotations for mini_val split from nuScenes version: v1.0-mini
  0%|          | 0/81 [00:00<?, ?it/s] 59%|█████▉    | 48/81 [00:00<00:00, 479.92it/s]100%|██████████| 81/81 [00:00<00:00, 448.63it/s]
Loaded ground truth annotations for 81 samples.
Filtering predictions
=> Original number of boxes: 15431
=> After distance based filtering: 15423
=> After LIDAR and RADAR points based filtering: 15423
=> After bike rack filtering: 15423
Filtering ground truth annotations
=> Original number of boxes: 4441
=> After distance based filtering: 3785
=> After LIDAR and RADAR points based filtering: 3393
=> After bike rack filtering: 3393
Accumulating metric data...
Calculating metrics...
Saving metrics to: val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox
mAP: 0.0000
mATE: 1.0241
mASE: 0.9813
mAOE: 1.0484
mAVE: 1.0120
mAAE: 0.9878
NDS: 0.0031
Eval time: 3.1s

Per-class results:
Object Class	AP	ATE	ASE	AOE	AVE	AAE
car	0.000	1.000	1.000	1.000	1.000	1.000
truck	0.000	1.000	1.000	1.000	1.000	1.000
bus	0.000	1.000	1.000	1.000	1.000	1.000
trailer	0.000	1.000	1.000	1.000	1.000	1.000
construction_vehicle	0.000	1.000	1.000	1.000	1.000	1.000
pedestrian	0.000	1.241	0.813	1.435	1.096	0.903
motorcycle	0.000	1.000	1.000	1.000	1.000	1.000
bicycle	0.000	1.000	1.000	1.000	1.000	1.000
traffic_cone	0.000	1.000	1.000	nan	nan	nan
barrier	0.000	1.000	1.000	1.000	nan	nan
2024-05-27 12:57:29,684 - mmdet - INFO - Exp name: bevformer_tiny.py
2024-05-27 12:57:29,684 - mmdet - INFO - Epoch(val) [2][81]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/car_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/car_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/car_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/car_trans_err: 1.0000, pts_bbox_NuScenes/car_scale_err: 1.0000, pts_bbox_NuScenes/car_orient_err: 1.0000, pts_bbox_NuScenes/car_vel_err: 1.0000, pts_bbox_NuScenes/car_attr_err: 1.0000, pts_bbox_NuScenes/mATE: 1.0241, pts_bbox_NuScenes/mASE: 0.9813, pts_bbox_NuScenes/mAOE: 1.0484, pts_bbox_NuScenes/mAVE: 1.0120, pts_bbox_NuScenes/mAAE: 0.9878, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/truck_trans_err: 1.0000, pts_bbox_NuScenes/truck_scale_err: 1.0000, pts_bbox_NuScenes/truck_orient_err: 1.0000, pts_bbox_NuScenes/truck_vel_err: 1.0000, pts_bbox_NuScenes/truck_attr_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_trans_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_scale_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_vel_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_attr_err: 1.0000, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bus_trans_err: 1.0000, pts_bbox_NuScenes/bus_scale_err: 1.0000, pts_bbox_NuScenes/bus_orient_err: 1.0000, pts_bbox_NuScenes/bus_vel_err: 1.0000, pts_bbox_NuScenes/bus_attr_err: 1.0000, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/trailer_trans_err: 1.0000, pts_bbox_NuScenes/trailer_scale_err: 1.0000, pts_bbox_NuScenes/trailer_orient_err: 1.0000, pts_bbox_NuScenes/trailer_vel_err: 1.0000, pts_bbox_NuScenes/trailer_attr_err: 1.0000, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/barrier_trans_err: 1.0000, pts_bbox_NuScenes/barrier_scale_err: 1.0000, pts_bbox_NuScenes/barrier_orient_err: 1.0000, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/motorcycle_trans_err: 1.0000, pts_bbox_NuScenes/motorcycle_scale_err: 1.0000, pts_bbox_NuScenes/motorcycle_orient_err: 1.0000, pts_bbox_NuScenes/motorcycle_vel_err: 1.0000, pts_bbox_NuScenes/motorcycle_attr_err: 1.0000, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 1.0000, pts_bbox_NuScenes/bicycle_scale_err: 1.0000, pts_bbox_NuScenes/bicycle_orient_err: 1.0000, pts_bbox_NuScenes/bicycle_vel_err: 1.0000, pts_bbox_NuScenes/bicycle_attr_err: 1.0000, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/pedestrian_trans_err: 1.2412, pts_bbox_NuScenes/pedestrian_scale_err: 0.8129, pts_bbox_NuScenes/pedestrian_orient_err: 1.4352, pts_bbox_NuScenes/pedestrian_vel_err: 1.0961, pts_bbox_NuScenes/pedestrian_attr_err: 0.9026, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/traffic_cone_trans_err: 1.0000, pts_bbox_NuScenes/traffic_cone_scale_err: 1.0000, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.0031, pts_bbox_NuScenes/mAP: 0.0000
2024-05-27 12:58:07,284 - mmdet - INFO - Epoch [3][50/323]	lr: 1.966e-04, eta: 1:16:09, time: 0.752, data_time: 0.328, memory: 3504, loss_cls: 1.2462, loss_bbox: 1.7613, d0.loss_cls: 1.2011, d0.loss_bbox: 1.6192, d1.loss_cls: 1.2450, d1.loss_bbox: 1.6634, d2.loss_cls: 1.2474, d2.loss_bbox: 1.7349, d3.loss_cls: 1.2409, d3.loss_bbox: 1.6988, d4.loss_cls: 1.2423, d4.loss_bbox: 1.7736, loss: 17.6741, grad_norm: 37.8434
2024-05-27 12:58:40,658 - mmdet - INFO - Epoch [3][100/323]	lr: 1.966e-04, eta: 1:15:46, time: 0.667, data_time: 0.244, memory: 3504, loss_cls: 1.2254, loss_bbox: 1.7415, d0.loss_cls: 1.1365, d0.loss_bbox: 1.5938, d1.loss_cls: 1.2213, d1.loss_bbox: 1.6719, d2.loss_cls: 1.2248, d2.loss_bbox: 1.7324, d3.loss_cls: 1.2262, d3.loss_bbox: 1.7238, d4.loss_cls: 1.2227, d4.loss_bbox: 1.7393, loss: 17.4596, grad_norm: 37.0136
2024-05-27 12:59:14,550 - mmdet - INFO - Epoch [3][150/323]	lr: 1.966e-04, eta: 1:15:26, time: 0.678, data_time: 0.257, memory: 3504, loss_cls: 1.2560, loss_bbox: 1.8492, d0.loss_cls: 1.1898, d0.loss_bbox: 1.6471, d1.loss_cls: 1.2492, d1.loss_bbox: 1.6175, d2.loss_cls: 1.2550, d2.loss_bbox: 1.6573, d3.loss_cls: 1.2588, d3.loss_bbox: 1.6466, d4.loss_cls: 1.2563, d4.loss_bbox: 1.6530, loss: 17.5358, grad_norm: 41.8073
2024-05-27 12:59:47,739 - mmdet - INFO - Epoch [3][200/323]	lr: 1.966e-04, eta: 1:14:59, time: 0.664, data_time: 0.245, memory: 3504, loss_cls: 1.2056, loss_bbox: 1.6647, d0.loss_cls: 1.0826, d0.loss_bbox: 1.5706, d1.loss_cls: 1.1827, d1.loss_bbox: 1.5756, d2.loss_cls: 1.1956, d2.loss_bbox: 1.6265, d3.loss_cls: 1.1929, d3.loss_bbox: 1.6278, d4.loss_cls: 1.1912, d4.loss_bbox: 1.6255, loss: 16.7413, grad_norm: 33.8866
2024-05-27 13:00:21,932 - mmdet - INFO - Epoch [3][250/323]	lr: 1.966e-04, eta: 1:14:38, time: 0.684, data_time: 0.261, memory: 3504, loss_cls: 1.1891, loss_bbox: 1.6693, d0.loss_cls: 1.0888, d0.loss_bbox: 1.5714, d1.loss_cls: 1.1732, d1.loss_bbox: 1.5801, d2.loss_cls: 1.1869, d2.loss_bbox: 1.5942, d3.loss_cls: 1.1945, d3.loss_bbox: 1.6820, d4.loss_cls: 1.1843, d4.loss_bbox: 1.6803, loss: 16.7943, grad_norm: 36.8034
2024-05-27 13:00:54,888 - mmdet - INFO - Epoch [3][300/323]	lr: 1.966e-04, eta: 1:14:08, time: 0.659, data_time: 0.241, memory: 3504, loss_cls: 1.2787, loss_bbox: 1.6695, d0.loss_cls: 1.1254, d0.loss_bbox: 1.6329, d1.loss_cls: 1.2586, d1.loss_bbox: 1.6274, d2.loss_cls: 1.2801, d2.loss_bbox: 1.6783, d3.loss_cls: 1.2730, d3.loss_bbox: 1.7353, d4.loss_cls: 1.2780, d4.loss_bbox: 1.6670, loss: 17.5040, grad_norm: 42.3139
2024-05-27 13:01:09,331 - mmdet - INFO - Saving checkpoint at 3 epochs
[                                                  ] 0/81, elapsed: 0s, ETA:[                                  ] 1/81, 1.6 task/s, elapsed: 1s, ETA:    50s[                                  ] 2/81, 2.8 task/s, elapsed: 1s, ETA:    28s[>                                 ] 3/81, 3.8 task/s, elapsed: 1s, ETA:    21s[>                                 ] 4/81, 4.5 task/s, elapsed: 1s, ETA:    17s[>>                                ] 5/81, 4.3 task/s, elapsed: 1s, ETA:    18s[>>                                ] 6/81, 4.8 task/s, elapsed: 1s, ETA:    16s[>>                                ] 7/81, 5.1 task/s, elapsed: 1s, ETA:    14s[>>>                               ] 8/81, 5.5 task/s, elapsed: 1s, ETA:    13s[>>>                               ] 9/81, 5.3 task/s, elapsed: 2s, ETA:    13s[>>>>                             ] 10/81, 5.6 task/s, elapsed: 2s, ETA:    13s[>>>>                             ] 11/81, 5.9 task/s, elapsed: 2s, ETA:    12s[>>>>                             ] 12/81, 6.2 task/s, elapsed: 2s, ETA:    11s[>>>>>                            ] 13/81, 5.8 task/s, elapsed: 2s, ETA:    12s[>>>>>                            ] 14/81, 6.0 task/s, elapsed: 2s, ETA:    11s[>>>>>>                           ] 15/81, 6.2 task/s, elapsed: 2s, ETA:    11s[>>>>>>                           ] 16/81, 6.3 task/s, elapsed: 3s, ETA:    10s[>>>>>>                           ] 17/81, 6.2 task/s, elapsed: 3s, ETA:    10s[>>>>>>>                          ] 18/81, 6.3 task/s, elapsed: 3s, ETA:    10s[>>>>>>>                          ] 19/81, 6.5 task/s, elapsed: 3s, ETA:    10s[>>>>>>>>                         ] 20/81, 6.7 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>                         ] 21/81, 6.4 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>                         ] 22/81, 6.6 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>>                        ] 23/81, 6.7 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>>                        ] 24/81, 6.8 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>                       ] 25/81, 6.5 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>                       ] 26/81, 6.6 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 27/81, 6.7 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 28/81, 6.8 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>                      ] 29/81, 6.7 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>>                     ] 30/81, 6.8 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>>                     ] 31/81, 6.9 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>                    ] 32/81, 7.0 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>                    ] 33/81, 6.8 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>                    ] 34/81, 6.9 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>                   ] 35/81, 6.9 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>                   ] 36/81, 7.0 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>                  ] 37/81, 6.9 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>                  ] 38/81, 6.9 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>                  ] 39/81, 7.0 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>                 ] 40/81, 7.1 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>                 ] 41/81, 7.0 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>>                ] 42/81, 7.0 task/s, elapsed: 6s, ETA:     6s[>>>>>>>>>>>>>>>>>                ] 43/81, 7.1 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>                ] 44/81, 7.1 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>               ] 45/81, 7.1 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>               ] 46/81, 7.1 task/s, elapsed: 6s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 47/81, 7.2 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 48/81, 7.2 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>              ] 49/81, 7.1 task/s, elapsed: 7s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>             ] 50/81, 7.1 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>             ] 51/81, 7.2 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>            ] 52/81, 7.2 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>            ] 53/81, 7.3 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 7.3 task/s, elapsed: 7s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 7.1 task/s, elapsed: 8s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>           ] 56/81, 7.2 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 7.2 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 7.2 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 7.2 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>         ] 61/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 7.3 task/s, elapsed: 8s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 7.2 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 7.2 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 66/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 7.2 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 7.3 task/s, elapsed: 9s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 7.3 task/s, elapsed: 10s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 7.2 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 7.2 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 7.3 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 7.3 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 7.3 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 7.3 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 7.3 task/s, elapsed: 10s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 7.4 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 7.4 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 7.5 task/s, elapsed: 11s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 7.5 task/s, elapsed: 11s, ETA:     0s
Formating bboxes of pts_bbox
Start to convert detection format...
[                                                  ] 0/81, elapsed: 0s, ETA:[                                 ] 1/81, 27.7 task/s, elapsed: 0s, ETA:     3s[                                 ] 2/81, 27.6 task/s, elapsed: 0s, ETA:     3s[>                                ] 3/81, 27.6 task/s, elapsed: 0s, ETA:     3s[>                                ] 4/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>                               ] 5/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>                               ] 6/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>                               ] 7/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>>                              ] 8/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>>                              ] 9/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>>                             ] 10/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>>>                            ] 11/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>>>                            ] 12/81, 27.5 task/s, elapsed: 0s, ETA:     3s[>>>>>                           ] 13/81, 27.5 task/s, elapsed: 0s, ETA:     2s[>>>>>                           ] 14/81, 27.5 task/s, elapsed: 1s, ETA:     2s[>>>>>                           ] 15/81, 27.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>                          ] 16/81, 27.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>                          ] 17/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 18/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 19/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>                         ] 20/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 21/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>                        ] 22/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 23/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 24/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>                       ] 25/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 26/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>                      ] 27/81, 27.7 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 28/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 29/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>                     ] 30/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 31/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>                    ] 32/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 33/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 34/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                   ] 35/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>                  ] 36/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>                  ] 37/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>>                 ] 38/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>>                 ] 39/81, 27.6 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>>                 ] 40/81, 27.6 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 41/81, 27.6 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 42/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>                ] 43/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 44/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>               ] 45/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 46/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 47/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>              ] 48/81, 27.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 49/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>             ] 50/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 51/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 52/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>            ] 53/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 54/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>           ] 55/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 56/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 57/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>          ] 58/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 59/81, 27.8 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>         ] 60/81, 25.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 61/81, 25.6 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 62/81, 25.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 63/81, 25.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 64/81, 25.7 task/s, elapsed: 2s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 65/81, 25.8 task/s, elapsed: 3s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 66/81, 25.8 task/s, elapsed: 3s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 67/81, 25.8 task/s, elapsed: 3s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 68/81, 25.9 task/s, elapsed: 3s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 69/81, 25.9 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 70/81, 25.9 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 71/81, 25.9 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 72/81, 26.0 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 73/81, 26.0 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 74/81, 26.0 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 75/81, 26.0 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 76/81, 26.1 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 77/81, 26.1 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 78/81, 26.1 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 79/81, 26.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 80/81, 26.2 task/s, elapsed: 3s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 26.2 task/s, elapsed: 3s, ETA:     0s
Results writes to val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox/results_nusc.json
Evaluating bboxes of pts_bbox
======
Loading NuScenes tables for version v1.0-mini...
23 category,
8 attribute,
4 visibility,
911 instance,
12 sensor,
120 calibrated_sensor,
31206 ego_pose,
8 log,
10 scene,
404 sample,
31206 sample_data,
18538 sample_annotation,
4 map,
Done loading in 0.340 seconds.
======
Reverse indexing ...
Done reverse indexing in 0.1 seconds.
======
Initializing nuScenes detection evaluation
Loaded results from val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox/results_nusc.json. Found detections for 81 samples.
Loading annotations for mini_val split from nuScenes version: v1.0-mini
  0%|          | 0/81 [00:00<?, ?it/s] 60%|██████    | 49/81 [00:00<00:00, 488.12it/s]100%|██████████| 81/81 [00:00<00:00, 460.09it/s]
Loaded ground truth annotations for 81 samples.
Filtering predictions
=> Original number of boxes: 23417
=> After distance based filtering: 23414
=> After LIDAR and RADAR points based filtering: 23414
=> After bike rack filtering: 23414
Filtering ground truth annotations
=> Original number of boxes: 4441
=> After distance based filtering: 3785
=> After LIDAR and RADAR points based filtering: 3393
=> After bike rack filtering: 3393
Accumulating metric data...
Calculating metrics...
Saving metrics to: val/./work_dirs/bevformer_tiny/Mon_May_27_12_49_23_2024/pts_bbox
mAP: 0.0000
mATE: 1.0326
mASE: 0.9745
mAOE: 1.0698
mAVE: 0.9346
mAAE: 0.8882
NDS: 0.0203
Eval time: 6.3s

Per-class results:
Object Class	AP	ATE	ASE	AOE	AVE	AAE
car	0.000	1.326	0.745	1.628	0.477	0.105
truck	0.000	1.000	1.000	1.000	1.000	1.000
bus	0.000	1.000	1.000	1.000	1.000	1.000
trailer	0.000	1.000	1.000	1.000	1.000	1.000
construction_vehicle	0.000	1.000	1.000	1.000	1.000	1.000
pedestrian	0.000	1.000	1.000	1.000	1.000	1.000
motorcycle	0.000	1.000	1.000	1.000	1.000	1.000
bicycle	0.000	1.000	1.000	1.000	1.000	1.000
traffic_cone	0.000	1.000	1.000	nan	nan	nan
barrier	0.000	1.000	1.000	1.000	nan	nan
2024-05-27 13:01:36,419 - mmdet - INFO - Exp name: bevformer_tiny.py
2024-05-27 13:01:36,419 - mmdet - INFO - Epoch(val) [3][81]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/car_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/car_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/car_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/car_trans_err: 1.3256, pts_bbox_NuScenes/car_scale_err: 0.7450, pts_bbox_NuScenes/car_orient_err: 1.6281, pts_bbox_NuScenes/car_vel_err: 0.4770, pts_bbox_NuScenes/car_attr_err: 0.1054, pts_bbox_NuScenes/mATE: 1.0326, pts_bbox_NuScenes/mASE: 0.9745, pts_bbox_NuScenes/mAOE: 1.0698, pts_bbox_NuScenes/mAVE: 0.9346, pts_bbox_NuScenes/mAAE: 0.8882, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/truck_trans_err: 1.0000, pts_bbox_NuScenes/truck_scale_err: 1.0000, pts_bbox_NuScenes/truck_orient_err: 1.0000, pts_bbox_NuScenes/truck_vel_err: 1.0000, pts_bbox_NuScenes/truck_attr_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/construction_vehicle_trans_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_scale_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_orient_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_vel_err: 1.0000, pts_bbox_NuScenes/construction_vehicle_attr_err: 1.0000, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bus_trans_err: 1.0000, pts_bbox_NuScenes/bus_scale_err: 1.0000, pts_bbox_NuScenes/bus_orient_err: 1.0000, pts_bbox_NuScenes/bus_vel_err: 1.0000, pts_bbox_NuScenes/bus_attr_err: 1.0000, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/trailer_trans_err: 1.0000, pts_bbox_NuScenes/trailer_scale_err: 1.0000, pts_bbox_NuScenes/trailer_orient_err: 1.0000, pts_bbox_NuScenes/trailer_vel_err: 1.0000, pts_bbox_NuScenes/trailer_attr_err: 1.0000, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/barrier_trans_err: 1.0000, pts_bbox_NuScenes/barrier_scale_err: 1.0000, pts_bbox_NuScenes/barrier_orient_err: 1.0000, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/motorcycle_trans_err: 1.0000, pts_bbox_NuScenes/motorcycle_scale_err: 1.0000, pts_bbox_NuScenes/motorcycle_orient_err: 1.0000, pts_bbox_NuScenes/motorcycle_vel_err: 1.0000, pts_bbox_NuScenes/motorcycle_attr_err: 1.0000, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/bicycle_trans_err: 1.0000, pts_bbox_NuScenes/bicycle_scale_err: 1.0000, pts_bbox_NuScenes/bicycle_orient_err: 1.0000, pts_bbox_NuScenes/bicycle_vel_err: 1.0000, pts_bbox_NuScenes/bicycle_attr_err: 1.0000, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/pedestrian_trans_err: 1.0000, pts_bbox_NuScenes/pedestrian_scale_err: 1.0000, pts_bbox_NuScenes/pedestrian_orient_err: 1.0000, pts_bbox_NuScenes/pedestrian_vel_err: 1.0000, pts_bbox_NuScenes/pedestrian_attr_err: 1.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.0000, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.0000, pts_bbox_NuScenes/traffic_cone_trans_err: 1.0000, pts_bbox_NuScenes/traffic_cone_scale_err: 1.0000, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.0203, pts_bbox_NuScenes/mAP: 0.0000
